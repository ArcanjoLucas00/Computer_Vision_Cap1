{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conexão Drive-Git e Clonagem do Repo no Drive\n"
      ],
      "metadata": {
        "id": "NM49gYJk8lz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Monta o Google Drive (necessário para ter acesso à pasta de destino)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vo4d1ge8APV",
        "outputId": "af847ca2-39ad-4e57-f564-d86e811f4f58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados do Git\n",
        "\n",
        "github_token = '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'\n",
        "github_username = 'ArcanjoLucas00'\n",
        "repo_name = 'Computer_Vision_Cap1'\n",
        "\n",
        "# Caminho para a pasta no Google Drive que precisa ser atualizada\n",
        "drive_folder = '/content/drive/MyDrive/computer_vision_cap1'\n",
        "\n",
        "# 2. Clona a versão mais recente do seu repositório do GitHub\n",
        "# O comando 'rm -rf' garante que, se a pasta já existir de uma execução anterior,\n",
        "# ela seja removida para clonar uma cópia limpa e nova.\n",
        "!rm -rf /content/{repo_name}\n",
        "!git clone https://{github_username}:{github_token}@github.com/{github_username}/{repo_name}.git\n",
        "\n",
        "# 3. Sincroniza os arquivos do repositório clonado PARA a pasta do Google Drive\n",
        "# A origem agora é a pasta do repositório e o destino é a pasta do Drive.\n",
        "# A opção '--delete' remove arquivos do Drive que não existem mais no repositório,\n",
        "# tornando a pasta do Drive um espelho exato do seu repo.\n",
        "print(\"\\nIniciando a sincronização do GitHub para o Google Drive...\")\n",
        "!rsync -av --delete \"/content/{repo_name}/\" \"{drive_folder}/\"\n",
        "print(\"\\nSincronização concluída com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h8om_k-Z5jNN",
        "outputId": "393be269-15b9-42ee-f856-96bb1d1f47f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Computer_Vision_Cap1'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 143 (delta 4), reused 118 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (143/143), 4.52 MiB | 36.43 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "\n",
            "Iniciando a sincronização do GitHub para o Google Drive...\n",
            "sending incremental file list\n",
            "./\n",
            "README.md\n",
            ".git/\n",
            ".git/HEAD\n",
            ".git/config\n",
            ".git/description\n",
            ".git/index\n",
            ".git/packed-refs\n",
            ".git/branches/\n",
            ".git/hooks/\n",
            ".git/hooks/applypatch-msg.sample\n",
            ".git/hooks/commit-msg.sample\n",
            ".git/hooks/fsmonitor-watchman.sample\n",
            ".git/hooks/post-update.sample\n",
            ".git/hooks/pre-applypatch.sample\n",
            ".git/hooks/pre-commit.sample\n",
            ".git/hooks/pre-merge-commit.sample\n",
            ".git/hooks/pre-push.sample\n",
            ".git/hooks/pre-rebase.sample\n",
            ".git/hooks/pre-receive.sample\n",
            ".git/hooks/prepare-commit-msg.sample\n",
            ".git/hooks/push-to-checkout.sample\n",
            ".git/hooks/update.sample\n",
            ".git/info/\n",
            ".git/info/exclude\n",
            ".git/logs/\n",
            ".git/logs/HEAD\n",
            ".git/logs/refs/\n",
            ".git/logs/refs/heads/\n",
            ".git/logs/refs/heads/main\n",
            ".git/logs/refs/remotes/\n",
            ".git/logs/refs/remotes/origin/\n",
            ".git/logs/refs/remotes/origin/HEAD\n",
            ".git/objects/\n",
            ".git/objects/info/\n",
            ".git/objects/pack/\n",
            ".git/objects/pack/pack-868fef907d5f647d077e4d351fbe1ebd8c7c768b.idx\n",
            ".git/objects/pack/pack-868fef907d5f647d077e4d351fbe1ebd8c7c768b.pack\n",
            ".git/refs/\n",
            ".git/refs/heads/\n",
            ".git/refs/heads/main\n",
            ".git/refs/remotes/\n",
            ".git/refs/remotes/origin/\n",
            ".git/refs/remotes/origin/HEAD\n",
            ".git/refs/tags/\n",
            "Computer_Vision_Cap1/\n",
            "Computer_Vision_Cap1/chaves/\n",
            "Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-12-08-37-05.json\n",
            "Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-12-08-37-20.json\n",
            "Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-14-02-45-54.json\n",
            "Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-14-03-27-51.json\n",
            "Computer_Vision_Cap1/chaves/test/\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0003_Layer 60.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0004_Layer 59.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0037_Layer 8.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0038_Layer 5.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0039_Layer 4.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0040_Layer 3.jpg\n",
            "Computer_Vision_Cap1/chaves/train/\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0005_Layer 58.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0006_Layer 57.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0007_Layer 56.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0008_Layer 55.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0009_Layer 54.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0010_Layer 53.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0011_Layer 52.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0012_Layer 51.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0013_Layer 50.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0014_Layer 49.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0015_Layer 32.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0016_Layer 33.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0017_Layer 30.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0018_Layer 29.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0019_Layer 28.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0020_Layer 27.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0021_Layer 26.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0022_Layer 25.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0023_Layer 24.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0024_Layer 23.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0025_Layer 22.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0026_Layer 21.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0027_Layer 20.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0028_Layer 17.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0029_Layer 16.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0030_Layer 15.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0031_Layer 14.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0032_Layer 13.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0033_Layer 12.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0034_Layer 11.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0035_Layer 10.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0036_Layer 9.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0044_Layer 1.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0045_Layer 45.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0046_Layer 44.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0047_Layer 43.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0048_Layer 41.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0049_Layer 39.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0050_Layer 48.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0051_Layer 47.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0000_Layer 63.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0001_Layer 62.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0002_Layer 61.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0041_Layer 2.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0042_Layer 35.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0043_Layer 34.jpg\n",
            "Computer_Vision_Cap1/xicaras/\n",
            "Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-13-12-41-09.json\n",
            "Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-13-12-41-18.json\n",
            "Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-14-04-17-44.json\n",
            "Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-14-04-32-33.json\n",
            "Computer_Vision_Cap1/xicaras/test/\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0006_Layer 41.jpg\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0009_Layer 38.jpg\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0010_Layer 37.jpg\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0029_Layer 18.jpg\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0038_Layer 9.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0000_Layer 47.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0001_Layer 46.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0002_Layer 45.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0003_Layer 44.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0004_Layer 43.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0005_Layer 42.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0007_Layer 40.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0008_Layer 39.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0012_Layer 35.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0014_Layer 33.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0016_Layer 31.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0017_Layer 30.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0018_Layer 29.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0019_Layer 28.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0020_Layer 27.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0021_Layer 26.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0022_Layer 25.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0023_Layer 24.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0024_Layer 23.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0025_Layer 22.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0026_Layer 21.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0028_Layer 19.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0031_Layer 16.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0032_Layer 15.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0033_Layer 14.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0034_Layer 13.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0035_Layer 12.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0036_Layer 11.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0037_Layer 10.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0039_Layer 8.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0040_Layer 7.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0041_Layer 6.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0042_Layer 5.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0043_Layer 4.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0044_Layer 3.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0045_Layer 2.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0046_Layer 1.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0047_Background copy.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0011_Layer 36.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0013_Layer 34.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0015_Layer 32.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0027_Layer 20.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0030_Layer 17.jpg\n",
            "\n",
            "sent 10,961,531 bytes  received 2,736 bytes  1,289,913.76 bytes/sec\n",
            "total size is 10,948,628  speedup is 1.00\n",
            "\n",
            "Sincronização concluída com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 1: Montar o Google Drive e Instalar Dependências\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Monta o Google Drive no ambiente do Colab\n",
        "# Uma janela de autenticação irá aparecer para permitir o acesso.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Instala a biblioteca Ultralytics, que contém o YOLOv8.\n",
        "# O '-q' é para uma instalação silenciosa.\n",
        "!pip install ultralytics -q\n",
        "\n",
        "print(\"Drive montado e Ultralytics instalado com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zIiJfQX-ws1",
        "outputId": "8e4a5793-a1a2-4b0e-f339-27ab58f4c2ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDrive montado e Ultralytics instalado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuração dos Caminhos e Preparação do Dataset"
      ],
      "metadata": {
        "id": "8WzXpn4Y-_h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 2: Configuração dos Caminhos e Preparação do Dataset (VERSÃO FINAL CORRIGIDA)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Defina seus caminhos aqui ---\n",
        "# O caminho para as imagens agora aponta para a subpasta 'train'\n",
        "gdrive_image_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/train'\n",
        "\n",
        "# O caminho para o arquivo JSON permanece na pasta 'chaves'\n",
        "gdrive_json_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-12-08-37-20.json'\n",
        "\n",
        "# --- Criação das pastas locais no Colab ---\n",
        "base_dir = '/content/yolo_dataset'\n",
        "images_train_dir = os.path.join(base_dir, 'images', 'train')\n",
        "labels_train_dir = os.path.join(base_dir, 'labels', 'train')\n",
        "\n",
        "if os.path.exists(base_dir):\n",
        "    shutil.rmtree(base_dir)\n",
        "\n",
        "os.makedirs(images_train_dir, exist_ok=True)\n",
        "os.makedirs(labels_train_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Estrutura de pastas criada em: {base_dir}\")\n",
        "\n",
        "# --- Carregando o arquivo de anotações ---\n",
        "with open(gdrive_json_path, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# --- Processamento das Anotações e Imagens ---\n",
        "images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "class_names = list(categories_info.values())\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(f\"Dataset contém {num_classes} classe(s): {', '.join(class_names)}\")\n",
        "\n",
        "print(\"\\nProcessando anotações e copiando imagens...\")\n",
        "for ann in tqdm(coco_data['annotations']):\n",
        "    image_id = ann['image_id']\n",
        "    category_id = ann['category_id']\n",
        "    bbox = ann['bbox']\n",
        "\n",
        "    file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "    x_min, y_min, bbox_w, bbox_h = bbox\n",
        "    x_center = (x_min + bbox_w / 2) / img_w\n",
        "    y_center = (y_min + bbox_h / 2) / img_h\n",
        "    norm_w = bbox_w / img_w\n",
        "    norm_h = bbox_h / img_h\n",
        "\n",
        "    yolo_class_id = category_id - 1\n",
        "    yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "\n",
        "    label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "\n",
        "    with open(os.path.join(labels_train_dir, label_file_name), 'a') as f:\n",
        "        f.write(yolo_format_str)\n",
        "\n",
        "    # **CORREÇÃO APLICADA AQUI**\n",
        "    # Agora o script busca a imagem na pasta correta ('.../chaves/train/')\n",
        "    source_image_path = os.path.join(gdrive_image_path, file_name)\n",
        "    dest_image_path = os.path.join(images_train_dir, file_name)\n",
        "    if not os.path.exists(dest_image_path):\n",
        "        shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "print(\"\\nPreparação do dataset concluída!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuGP1Zpa-9Tr",
        "outputId": "8fc322aa-c31e-4db0-ae6c-fe49977fae25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrutura de pastas criada em: /content/yolo_dataset\n",
            "Dataset contém 1 classe(s): chave\n",
            "\n",
            "Processando anotações e copiando imagens...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45/45 [00:00<00:00, 204.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preparação do dataset concluída!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Criando o Arquivo de Configuração do Dataset (YAML)"
      ],
      "metadata": {
        "id": "TF2xPSJCArm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# As variáveis (base_dir, num_classes, class_names) foram definidas na Célula 2\n",
        "# Este código as utiliza para criar o arquivo de configuração.\n",
        "yaml_data = {\n",
        "    'train': os.path.join(base_dir, 'images', 'train'),\n",
        "    'val': os.path.join(base_dir, 'images', 'train'), # Usando o mesmo conjunto para validação por simplicidade\n",
        "    'nc': num_classes,                               # Número de classes (neste caso, 1)\n",
        "    'names': class_names                             # Nomes das classes (['chave'])\n",
        "}\n",
        "\n",
        "# Salva o arquivo de configuração no diretório principal do Colab\n",
        "yaml_file_path = '/content/dataset.yaml'\n",
        "with open(yaml_file_path, 'w') as f:\n",
        "    yaml.dump(yaml_data, f, sort_keys=False)\n",
        "\n",
        "print(f\"Arquivo de configuração '{yaml_file_path}' criado com sucesso:\")\n",
        "# O comando 'cat' exibe o conteúdo do arquivo que acabamos de criar\n",
        "!cat {yaml_file_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTNtjCD7BCHX",
        "outputId": "1b136991-57f9-4873-9e66-9f08573b59fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo de configuração '/content/dataset.yaml' criado com sucesso:\n",
            "train: /content/yolo_dataset/images/train\n",
            "val: /content/yolo_dataset/images/train\n",
            "nc: 1\n",
            "names:\n",
            "- chave\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicia o Treinamento do YOLOv8 - CHAVES"
      ],
      "metadata": {
        "id": "UtrQevH9BNZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Carrega um modelo pré-treinado.\n",
        "# 'yolov8n.pt' é o menor e mais rápido. Outras opções: yolov8s, yolov8m, yolov8l, yolov8x\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Inicia o treinamento do modelo\n",
        "# data: Caminho para o arquivo .yaml de configuração.\n",
        "# epochs: Número de vezes que o modelo verá o dataset inteiro. Comece com 25-50.\n",
        "# imgsz: Tamanho para o qual as imagens serão redimensionadas para o treinamento. 640 é um bom padrão.\n",
        "results = model.train(\n",
        "    data=yaml_file_path,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    project='/content/drive/MyDrive/YOLO_Models_Trained', # Nome da pasta onde os resultados serão salvos\n",
        "    name='chaves_detector'   # Nome da subpasta específica para este treinamento\n",
        ")\n",
        "\n",
        "print(\"\\nTreinamento concluído!\")\n",
        "print(\"Os resultados, incluindo os pesos do modelo treinado, estão na pasta 'yolo_training/chaves_detector'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny6_Ni2sBQnq",
        "outputId": "b806a8be-7ea4-4e13-dedb-d485355a3562"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.214 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset_xicaras.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=chaves_detector2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/YOLO_Models_Trained, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 592.3±320.1 MB/s, size: 64.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset_xicaras/labels/train.cache... 38 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 38/38 42.0Kit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 549.1±323.4 MB/s, size: 57.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_xicaras/labels/train.cache... 38 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 38/38 26.1Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50         0G      1.048       2.63      1.511         17        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 33.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.9s\n",
            "                   all         38         38    0.00333          1      0.387      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50         0G     0.9344      2.526      1.472         16        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38    0.00333          1      0.846       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50         0G     0.6286      2.076       1.28         16        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38    0.00333          1      0.967      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50         0G     0.6854      1.604       1.26         16        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38    0.00339          1      0.974      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50         0G     0.5843      1.368       1.18         15        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.5s\n",
            "                   all         38         38    0.00333          1      0.808      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50         0G     0.6126       1.41      1.258         10        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 32.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38    0.00333          1       0.68      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50         0G     0.5844      1.192      1.196         15        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38    0.00333          1      0.866      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50         0G      0.545      1.239      1.132         14        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.1s\n",
            "                   all         38         38    0.00333          1      0.916      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50         0G     0.5663      1.275      1.162         12        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.8s\n",
            "                   all         38         38      0.972      0.915      0.969      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50         0G     0.5157      1.093      1.098         15        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 32.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.8s\n",
            "                   all         38         38       0.96      0.921      0.967      0.584\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50         0G     0.5209      1.078      1.157         13        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38      0.956      0.567       0.95      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50         0G     0.4591     0.9774      1.037         24        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38          1      0.553       0.97      0.732\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50         0G     0.7485      1.251      1.308         13        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38          1      0.989      0.995      0.751\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50         0G     0.5743     0.9739      1.184         19        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 12.0s\n",
            "                   all         38         38       0.97      0.974      0.982      0.724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50         0G     0.6225      1.092       1.19         14        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 33.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.6s\n",
            "                   all         38         38      0.949      0.982      0.991      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50         0G     0.5765      1.034       1.14         17        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38      0.942          1      0.977      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50         0G     0.5928     0.9832       1.17         22        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.1s\n",
            "                   all         38         38      0.903       0.98      0.968      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50         0G     0.5998      1.041       1.18         16        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.9s\n",
            "                   all         38         38      0.935          1      0.991      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50         0G     0.6098      1.008      1.212         17        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.8s\n",
            "                   all         38         38      0.974      0.985      0.994      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50         0G     0.5767     0.9121      1.151         15        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 32.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.4s\n",
            "                   all         38         38      0.966      0.947      0.988       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50         0G     0.6013     0.9101      1.193         16        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.8s\n",
            "                   all         38         38      0.923      0.948      0.982      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50         0G     0.6174      1.055      1.228         12        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.1s\n",
            "                   all         38         38      0.926      0.992      0.977      0.764\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50         0G     0.5808     0.8921      1.165         17        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38      0.943      0.974      0.987      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50         0G     0.5628     0.9397      1.195         16        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.5s\n",
            "                   all         38         38      0.991      0.974      0.994      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50         0G     0.5805     0.8538      1.128         20        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38      0.973      0.961      0.982       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50         0G     0.6151     0.8979      1.193         13        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 32.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38      0.944          1      0.984      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50         0G     0.5381     0.8009      1.106         19        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38      0.925      0.974       0.98      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50         0G     0.5113     0.8248      1.129         16        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 14.1s\n",
            "                   all         38         38      0.951      0.921      0.985      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50         0G     0.9009      1.199      1.468         11        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.0s\n",
            "                   all         38         38      0.951      0.921      0.985      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50         0G     0.6968      1.044      1.267          9        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.9s\n",
            "                   all         38         38          1      0.999      0.995      0.821\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50         0G     0.5576     0.7937      1.102         17        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.4s\n",
            "                   all         38         38      0.974      0.994      0.994      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50         0G     0.6064     0.8772       1.19         15        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.0s\n",
            "                   all         38         38       0.97          1      0.994      0.826\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50         0G     0.4806     0.7763      1.051         20        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38       0.97          1      0.994      0.826\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50         0G     0.5195     0.8034      1.156         16        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38       0.97          1      0.994      0.814\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50         0G     0.5067     0.8011      1.125         17        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38      0.969          1      0.994      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50         0G     0.6201     0.9081      1.222         14        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38      0.994          1      0.995       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50         0G      0.529     0.7624      1.079         18        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 12.7s\n",
            "                   all         38         38      0.994          1      0.995       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50         0G     0.4779     0.7505      1.044         19        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 29.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.6s\n",
            "                   all         38         38      0.996          1      0.995      0.904\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50         0G      0.441     0.7505      1.038         17        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38      0.998          1      0.995      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50         0G     0.5067     0.7414      1.082         20        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 32.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38      0.998          1      0.995      0.902\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50         0G     0.3472       1.19      1.005          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38      0.998          1      0.995      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50         0G     0.3951       1.16      1.166          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38      0.998          1      0.995      0.915\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50         0G     0.3344      1.038     0.9934          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38      0.997          1      0.995      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50         0G     0.4144      1.239      1.153          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 31.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38      0.998          1      0.995      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50         0G      0.381       1.12      1.099          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 32.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 10.6s\n",
            "                   all         38         38      0.998          1      0.995      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50         0G     0.2994     0.9823     0.9791          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38      0.998          1      0.995      0.936\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50         0G     0.3103     0.9902     0.9947          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.0s\n",
            "                   all         38         38      0.998          1      0.995      0.957\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50         0G      0.276     0.9086     0.9067          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.0s\n",
            "                   all         38         38      0.998          1      0.995      0.974\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50         0G      0.284     0.9213     0.9377          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 32.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.9s\n",
            "                   all         38         38      0.998          1      0.995      0.974\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50         0G     0.3104     0.9198      1.004          6        640: 100% ━━━━━━━━━━━━ 3/3 0.1it/s 29.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 12.0s\n",
            "                   all         38         38      0.998          1      0.995      0.977\n",
            "\n",
            "50 epochs completed in 0.596 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2/weights/best.pt...\n",
            "Ultralytics 8.3.214 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.2it/s 11.1s\n",
            "                   all         38         38      0.998          1      0.995      0.977\n",
            "Speed: 3.0ms preprocess, 256.1ms inference, 0.0ms loss, 21.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2\u001b[0m\n",
            "\n",
            "Treinamento concluído!\n",
            "Os resultados, incluindo os pesos do modelo treinado, estão na pasta 'yolo_training/chaves_detector'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Treino - Chaves - 25 Épocas\n",
        "\n",
        "### mAP50(0.97) - Esta é a métrica principal para detecção de objetos. Um valor de 97% é excelente. Ele mede a precisão do modelo em acertar a localização das \"chaves\". Simplificando, o modelo está acertando quase sempre.\n",
        "\n",
        "\n",
        "### mAP50-95(0.866) - Esta é uma métrica mais rigorosa, que mede a precisão em diferentes níveis de exigência de sobreposição. Um valor de 86.6% aqui é muito forte e indica que as caixas delimitadoras (os retângulos) que o modelo desenha estão bem justas aos objetos."
      ],
      "metadata": {
        "id": "HBHrnwmHG-4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Treino - Chaves - 50 Épocas\n",
        "\n",
        "### Box(P) - Precisão (0.998): Resultado Praticamente Perfeito. Uma precisão de 99.8% indica que quase todas as detecções que o modelo fez estavam corretas. Ele praticamente não cometeu erros de \"falso positivo\" (identificar um objeto que não era uma chave). Isso o torna extremamente confiável.\n",
        "\n",
        "### Box(R) - Recall (1): Resultado Perfeito. Um recall de 100% é a pontuação máxima. Significa que, de todas as chaves que realmente existiam nas 38 imagens, o modelo encontrou todas. Não deixou nenhuma passar despercebida, o que é um feito fantástico.\n",
        "\n",
        "### mAP50 (0.995): Desempenho de Elite. A métrica principal, que combina precisão e recall, atingiu 99.5%. Este é um resultado de altíssima qualidade, confirmando que o modelo localiza as chaves com uma precisão quase perfeita.\n",
        "\n",
        "### mAP50-95 (0.977): Excepcional e Robusto. Este é, talvez, o resultado mais impressionante. Um valor de 97.7% nesta métrica, que é muito mais rigorosa, é excepcional. Ele nos diz que as caixas delimitadoras que o modelo desenha não estão apenas no lugar certo, mas também estão muito bem ajustadas ao tamanho e formato das chaves, mesmo sob critérios de avaliação muito exigentes.\n"
      ],
      "metadata": {
        "id": "9fa2INmdUJb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Célula para Validação Dedicada - CHAVES"
      ],
      "metadata": {
        "id": "7LDWIMPyIXaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA DE VALIDAÇÃO FINAL\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"--- Iniciando o Processo de Validação com Dataset Dedicado ---\")\n",
        "\n",
        "# --- 1. CONFIGURAÇÃO DOS CAMINHOS ---\n",
        "gdrive_val_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/validation'\n",
        "\n",
        "# Nome do seu novo arquivo COCO JSON correto\n",
        "gdrive_val_json_name = 'labels_my-project-name_2025-10-14-02-45-54.json'\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves'\n",
        "gdrive_val_json_path = os.path.join(gdrive_base_path, gdrive_val_json_name)\n",
        "\n",
        "model_path = '/content/yolo_training/chaves_detector/weights/best.pt'\n",
        "\n",
        "# --- 2. PREPARAÇÃO DO DATASET DE VALIDAÇÃO ---\n",
        "print(f\"\\n[PASSO 1/3] Preparando o dataset a partir de: {gdrive_val_path}\")\n",
        "\n",
        "base_dir_val = '/content/yolo_dataset_validation'\n",
        "images_val_dir = os.path.join(base_dir_val, 'images', 'val')\n",
        "labels_val_dir = os.path.join(base_dir_val, 'labels', 'val')\n",
        "\n",
        "if os.path.exists(base_dir_val): shutil.rmtree(base_dir_val)\n",
        "os.makedirs(images_val_dir, exist_ok=True)\n",
        "os.makedirs(labels_val_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    print(f\"Carregando anotações de: {gdrive_val_json_path}\")\n",
        "    with open(gdrive_val_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    if 'annotations' not in coco_data or 'images' not in coco_data or 'categories' not in coco_data:\n",
        "        raise ValueError(\"Erro: O arquivo JSON não parece estar no formato COCO.\")\n",
        "\n",
        "    images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "    categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    class_names = list(categories_info.values())\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\"Encontradas {len(coco_data['images'])} imagens e {len(coco_data['annotations'])} anotações no JSON.\")\n",
        "\n",
        "    valid_annotations_found = 0\n",
        "    for ann in tqdm(coco_data['annotations'], desc=\"Processando anotações\"):\n",
        "        if 'category_id' not in ann or 'bbox' not in ann:\n",
        "            continue\n",
        "\n",
        "        valid_annotations_found += 1\n",
        "        image_id = ann['image_id']\n",
        "        file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "        source_image_path = os.path.join(gdrive_val_path, file_name)\n",
        "        dest_image_path = os.path.join(images_val_dir, file_name)\n",
        "        if not os.path.exists(dest_image_path):\n",
        "            try:\n",
        "                shutil.copy(source_image_path, dest_image_path)\n",
        "            except FileNotFoundError:\n",
        "                print(f\"\\nAviso: A imagem '{file_name}' não foi encontrada em '{gdrive_val_path}' e será ignorada.\")\n",
        "                continue\n",
        "\n",
        "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "        with open(os.path.join(labels_val_dir, label_file_name), 'a') as f:\n",
        "            category_id = ann['category_id']\n",
        "            bbox = ann['bbox']\n",
        "            x_min, y_min, bbox_w, bbox_h = bbox\n",
        "            x_center = (x_min + bbox_w / 2) / img_w\n",
        "            y_center = (y_min + bbox_h / 2) / img_h\n",
        "            norm_w = bbox_w / img_w\n",
        "            norm_h = bbox_h / img_h\n",
        "            yolo_class_id = category_id - 1\n",
        "            yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "            f.write(yolo_format_str)\n",
        "\n",
        "    if valid_annotations_found == 0:\n",
        "        raise ValueError(\"Nenhuma anotação válida foi encontrada. Por favor, re-exporte no formato COCO.\")\n",
        "\n",
        "    print(\"Dataset de validação preparado com sucesso.\")\n",
        "\n",
        "    # --- 3. CRIAÇÃO DO ARQUIVO YAML ---\n",
        "    print(\"\\n[PASSO 2/3] Criando arquivo de configuração 'validation.yaml'\")\n",
        "    yaml_val_data = {\n",
        "        'train': images_val_dir,\n",
        "        'val': images_val_dir,\n",
        "        'nc': num_classes,\n",
        "        'names': class_names\n",
        "    }\n",
        "    yaml_val_file_path = '/content/validation.yaml'\n",
        "    with open(yaml_val_file_path, 'w') as f: yaml.dump(yaml_val_data, f, sort_keys=False)\n",
        "    !cat {yaml_val_file_path}\n",
        "\n",
        "    # --- 4. EXECUÇÃO DA VALIDAÇÃO ---\n",
        "    print(\"\\n[PASSO 3/3] Executando a validação...\")\n",
        "    model = YOLO(model_path)\n",
        "    validation_results = model.val(data=yaml_val_file_path)\n",
        "    print(\"\\n--- Processo de Validação Concluído ---\")\n",
        "\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(f\"\\nERRO CRÍTICO: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "91_3QoBrIZfj",
        "outputId": "a3928f51-35db-4068-f138-d0b0c0958449"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando o Processo de Validação com Dataset Dedicado ---\n",
            "\n",
            "[PASSO 1/3] Preparando o dataset a partir de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/validation\n",
            "Carregando anotações de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-14-02-45-54.json\n",
            "Encontradas 6 imagens e 6 anotações no JSON.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando anotações: 100%|██████████| 6/6 [00:00<00:00, 169.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset de validação preparado com sucesso.\n",
            "\n",
            "[PASSO 2/3] Criando arquivo de configuração 'validation.yaml'\n",
            "train: /content/yolo_dataset_validation/images/val\n",
            "val: /content/yolo_dataset_validation/images/val\n",
            "nc: 1\n",
            "names:\n",
            "- chave\n",
            "\n",
            "[PASSO 3/3] Executando a validação...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.214 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 681.7±196.5 MB/s, size: 50.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_validation/labels/val... 6 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 6/6 938.0it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset_validation/labels/val.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.5it/s 1.9s\n",
            "                   all          6          6       0.79      0.635      0.533      0.112\n",
            "Speed: 2.3ms preprocess, 284.7ms inference, 0.0ms loss, 16.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val5\u001b[0m\n",
            "\n",
            "--- Processo de Validação Concluído ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo da Validação Dedicada - 25 Épocas:\n",
        "\n",
        "### Box(P) - precisão (0.79): Das vezes que o modelo disse \"isto é uma chave\", ele estava certo em 79% das vezes. As outras 21% foram \"falsos positivos\" (ele detectou algo que não era uma chave, ou detectou a mesma chave mais de uma vez). Este é um bom número.\n",
        "\n",
        "### Box(R) - Recall(0.635): De todas as chaves que realmente existiam nas 6 imagens, o modelo conseguiu encontrar 63.5% delas. Os 36.5% restantes são \"falsos negativos\" (chaves que estavam na imagem, mas que o modelo não detectou).\n",
        "\n",
        "### mAP50(0.533):  Esta é a métrica principal. Ela representa a \"Média da Precisão Média\" com um limiar de acerto de 50%. Simplificando, é uma nota geral que equilibra a precisão e o recall. Um resultado de 53.3% é um ponto de partida razoável. Ele nos diz que o modelo aprendeu o conceito de \"chave\", mas ainda não é um especialista e comete erros ao ser exposto a imagens novas.\n",
        "\n",
        "### mAP50-95(0.112): Esta é uma métrica muito mais rigorosa, que calcula a média do mAP em diferentes níveis de exigência (de 50% até 95%). O valor baixo de 11.2% indica que, embora o modelo consiga encontrar a chave, as caixas delimitadoras (os retângulos) que ele desenha muitas vezes não estão perfeitamente alinhadas com o objeto real."
      ],
      "metadata": {
        "id": "Q0mmP5DNXQlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo da Validação Dedicada - 50 Épocas:\n",
        "\n",
        "### Box(P) - Precisão (0.79): De todas as vezes que o modelo disse \"isto é uma chave\", ele estava certo em 79% das vezes. Este é um bom resultado. Significa que o modelo tem uma alta confiança e raramente comete erros de \"falso positivo\" (identificar algo que não é uma chave).\n",
        "\n",
        "### Box(R) - Recall (0.635):De todas as chaves que realmente existiam nas imagens, o modelo conseguiu encontrar 63.5% delas.Este resultado é moderado. Significa que o modelo deixou de detectar cerca de 36.5% das chaves que estavam presentes (falsos negativos). Ele é bom em acertar quando detecta, mas não é tão bom em encontrar todos os objetos.\n",
        "\n",
        "### mAP50 (0.533): Esta é a métrica principal (Média da Precisão Média) é a nota geral que equilibra a precisão e o recall. O \"50\" significa que uma detecção é considerada \"correta\" se a caixa desenhada pelo modelo tiver pelo menos 50% de sobreposição com a caixa real. Uma pontuação de 53.3% indica que o modelo é um protótipo funcional. Ele claramente aprendeu o que é uma chave, mas ainda não é um especialista. Ele comete erros e tem espaço significativo para melhorar.\n",
        "\n",
        "### mAP50-95 (0.112):Esta é uma métrica muito mais rigorosa. Ela calcula a média do mAP em 10 níveis diferentes de exigência (de 50% a 95% de sobreposição). O valor baixo de 11.2% nos diz que as caixas delimitadoras que o modelo desenha não são muito precisas. Elas são boas o suficiente para passar no teste de 50% (por isso o mAP50 é 0.533), mas falham nos testes mais rigorosos."
      ],
      "metadata": {
        "id": "3mjtWbXbVMdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste: Modelo do Conjunto de Dados de Teste - CHAVES"
      ],
      "metadata": {
        "id": "aWl3Gkf9asGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA DE TESTE FINAL (com o caminho do modelo corrigido)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"--- Iniciando o Processo de Teste Final do Modelo ---\")\n",
        "\n",
        "# --- 1. CONFIGURAÇÃO DOS CAMINHOS ---\n",
        "gdrive_test_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/test'\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves'\n",
        "gdrive_test_json_name = 'labels_my-project-name_2025-10-14-03-27-51.json'\n",
        "gdrive_test_json_path = os.path.join(gdrive_base_path, gdrive_test_json_name)\n",
        "\n",
        "# **CORREÇÃO APLICADA AQUI: Apontando para a pasta correta no Drive**\n",
        "model_path = '/content/drive/MyDrive/YOLO_Models_Trained/chaves_detector/weights/best.pt'\n",
        "\n",
        "# --- 2. PREPARAÇÃO DO DATASET DE TESTE ---\n",
        "print(f\"\\n[PASSO 1/3] Preparando o dataset de teste a partir de: {gdrive_test_path}\")\n",
        "\n",
        "base_dir_test = '/content/yolo_dataset_test'\n",
        "images_test_dir = os.path.join(base_dir_test, 'images', 'test')\n",
        "labels_test_dir = os.path.join(base_dir_test, 'labels', 'test')\n",
        "\n",
        "if os.path.exists(base_dir_test): shutil.rmtree(base_dir_test)\n",
        "os.makedirs(images_test_dir, exist_ok=True)\n",
        "os.makedirs(labels_test_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    print(f\"Carregando anotações de: {gdrive_test_json_path}\")\n",
        "    with open(gdrive_test_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    if 'annotations' not in coco_data or 'images' not in coco_data or 'categories' not in coco_data:\n",
        "        raise ValueError(\"Erro: O arquivo JSON não parece estar no formato COCO.\")\n",
        "\n",
        "    images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "    categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    class_names = list(categories_info.values())\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\"Encontradas {len(coco_data['images'])} imagens e {len(coco_data['annotations'])} anotações no JSON de teste.\")\n",
        "\n",
        "    for ann in tqdm(coco_data['annotations'], desc=\"Processando anotações de teste\"):\n",
        "        if 'category_id' not in ann or 'bbox' not in ann: continue\n",
        "        image_id = ann['image_id']\n",
        "        file_name, img_w, img_h = images_info[image_id]\n",
        "        source_image_path = os.path.join(gdrive_test_path, file_name)\n",
        "        dest_image_path = os.path.join(images_test_dir, file_name)\n",
        "        if not os.path.exists(dest_image_path):\n",
        "            try: shutil.copy(source_image_path, dest_image_path)\n",
        "            except FileNotFoundError: continue\n",
        "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "        with open(os.path.join(labels_test_dir, label_file_name), 'a') as f:\n",
        "            category_id = ann['category_id']; bbox = ann['bbox']\n",
        "            x_min, y_min, bbox_w, bbox_h = bbox\n",
        "            x_center = (x_min + bbox_w / 2) / img_w; y_center = (y_min + bbox_h / 2) / img_h\n",
        "            norm_w = bbox_w / img_w; norm_h = bbox_h / img_h\n",
        "            yolo_class_id = category_id - 1\n",
        "            yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "            f.write(yolo_format_str)\n",
        "    print(\"Dataset de teste preparado com sucesso.\")\n",
        "\n",
        "    # --- 3. CRIAÇÃO DO ARQUIVO YAML ---\n",
        "    print(\"\\n[PASSO 2/3] Criando arquivo de configuração 'test.yaml'\")\n",
        "    yaml_test_data = {'train': images_test_dir, 'val': images_test_dir, 'nc': num_classes, 'names': class_names}\n",
        "    yaml_test_file_path = '/content/test.yaml'\n",
        "    with open(yaml_test_file_path, 'w') as f: yaml.dump(yaml_test_data, f, sort_keys=False)\n",
        "    !cat {yaml_test_file_path}\n",
        "\n",
        "    # --- 4. EXECUÇÃO DO TESTE FINAL ---\n",
        "    print(\"\\n[PASSO 3/3] Executando o teste final com o modelo treinado...\")\n",
        "    model = YOLO(model_path)\n",
        "    test_results = model.val(data=yaml_test_file_path)\n",
        "    print(\"\\n--- Processo de Teste Concluído ---\")\n",
        "\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(f\"\\nERRO CRÍTICO: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nTyNRj3ya11_",
        "outputId": "803d3beb-8f81-4276-b074-a3f0fb2c542f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando o Processo de Teste Final do Modelo ---\n",
            "\n",
            "[PASSO 1/3] Preparando o dataset de teste a partir de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/test\n",
            "Carregando anotações de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-14-03-27-51.json\n",
            "Encontradas 6 imagens e 6 anotações no JSON de teste.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando anotações de teste: 100%|██████████| 6/6 [00:00<00:00, 173.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset de teste preparado com sucesso.\n",
            "\n",
            "[PASSO 2/3] Criando arquivo de configuração 'test.yaml'\n",
            "train: /content/yolo_dataset_test/images/test\n",
            "val: /content/yolo_dataset_test/images/test\n",
            "nc: 1\n",
            "names:\n",
            "- chave\n",
            "\n",
            "[PASSO 3/3] Executando o teste final com o modelo treinado...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.214 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 892.8±141.6 MB/s, size: 56.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_test/labels/test... 6 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 6/6 667.0it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset_test/labels/test.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.4s\n",
            "                   all          6          6      0.564      0.441      0.534      0.157\n",
            "Speed: 3.2ms preprocess, 208.4ms inference, 0.0ms loss, 15.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val6\u001b[0m\n",
            "\n",
            "--- Processo de Teste Concluído ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Teste Final - 25 Épocas\n",
        "\n",
        "\n",
        "### Box(P) - Precisão (0.564): A precisão de 56.4% é um resultado modesto. Significa que, quando o modelo detectou uma \"chave\" nas imagens de teste, ele estava correto em pouco mais da metade das vezes. Os outros ~44% foram detecções incorretas (falsos positivos).\n",
        "\n",
        "### Box(R) - Recall (0.441): O recall de 44.1% indica que o modelo conseguiu encontrar menos da metade de todas as chaves que realmente existiam nas imagens de teste. Ele deixou passar um número significativo de objetos (falsos negativos).\n",
        "\n",
        "### mAP50 (0.534): Esta é a sua métrica principal e a \"nota final\" do modelo. Um resultado de 53.4% mostra que o modelo tem uma capacidade básica de identificar chaves, mas seu desempenho cai consideravelmente quando exposto a dados completamente novos, indicando que ele não é muito robusto.\n",
        "\n",
        "### mAP50-95 (0.157): A baixa pontuação de 15.7% nesta métrica mais rigorosa confirma que as detecções que o modelo acertou não foram muito precisas em termos de localização (as caixas delimitadoras não estavam bem ajustadas).\n",
        "\n",
        "\n",
        "### Considerações: Fazendo uma análise das imagens utilizadas em todas as etapas, foi constatado que as imagens utilizadas para o teste, possuiam um modelo de chave pouco visto pelo modelo nas etapas anteriores. Apesar de ainda haver reconhecimento, pode ter influenciado para um reconhecimento mais dificultoso, uma vez que não houveram tantos modelos parecidos para treino e validação.\n",
        "\n",
        "### A conclusão mais importante aqui é a grande diferença entre o desempenho do modelo nos dados de treino (~97%) e nos dados de teste (53%). Este fenômeno é chamado de overfitting (sobreadaptação).Significa que modelo \"decorou\" muito bem as imagens de treino, mas não aprendeu a \"generalizar\" o conceito de \"chave\" de forma eficaz. Quando ele vê imagens novas e um pouco diferentes no conjunto de teste, ele tem dificuldade em aplicar o que aprendeu.\n",
        "\n",
        "# Conclusão\n",
        "\n",
        "## Aumentar o Dataset é a solução mais importante para combater o overffiting. O modelo precisa de muito mais exemplos de chaves em ângulos diferentes, com iluminações diferentes, fundos variados e tipos distintos;\n",
        "\n",
        "## Podemos usar Data Augmentation e também, revisar a qualidade das anotações."
      ],
      "metadata": {
        "id": "YIvAtNMVbh_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Teste Final - 50 Épocas:\n",
        "\n",
        "### Box(P) - Precisão (0.564): Mede a exatidão das detecções. De todas as vezes que o modelo disse \"isto é uma chave\", ele estava certo em 56.4% das vezes. É um resultado moderado. Isso significa que para cada detecção correta, há quase uma detecção incorreta (falso positivo). O modelo ainda está um pouco \"confuso\".\n",
        "\n",
        "### Box(R) - Recall (0.441): Mede a capacidade do modelo de encontrar todos os objetos existentes. De todas as chaves que realmente estavam nas imagens, o modelo conseguiu encontrar apenas 44.1%.Este resultado é um ponto crítico. Significa que o modelo deixou de detectar mais da metade das chaves que estavam presentes (falsos negativos). Em muitas aplicações, um recall baixo pode ser um problema maior que uma precisão baixa.\n",
        "\n",
        "### mAP50 (0.534): É a métrica principal, que representa a nota geral do modelo, equilibrando precisão e recall. O \"50\" indica que uma detecção é considerada um acerto se a caixa prevista tiver pelo menos 50% de sobreposição com a caixa real. Uma pontuação de 53.4% classifica o modelo como um protótipo funcional. Ele aprendeu o conceito básico de \"chave\", mas ainda não é robusto o suficiente para ser considerado confiável, pois seu desempenho cai significativamente em dados novos.\n",
        "\n",
        "### mAP50-95 (0.157): Uma métrica muito mais rigorosa que mede o desempenho em níveis de exigência de sobreposição de 50% até 95%.O valor baixo de 15.7% confirma que as poucas detecções corretas que o modelo fez geralmente não estavam bem ajustadas ao objeto. As caixas delimitadoras estavam um pouco \"frouxas\".\n",
        "\n",
        "# Conclusão:\n",
        "\n",
        "### O modelo \"decorou\" muito bem as imagens de treino, mas não aprendeu a generalizar esse conhecimento de forma eficaz para novas imagens. Ele funciona, mas ainda não é confiável. O resultado, no entanto, é um excelente diagnóstico que aponta o caminho para melhorias, como aumentar significativamente a variedade e a quantidade de imagens de treino.\n"
      ],
      "metadata": {
        "id": "8VEFfNIvWKWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuração dos Caminhos e Preparação de Dados para o Dataset - XÍCARAS"
      ],
      "metadata": {
        "id": "RBkytZYbdmJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 2: Configuração dos Caminhos e Preparação do Dataset de XÍCARAS\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Definição dos novos caminhos para o dataset de xícaras ---\n",
        "# Caminho base para a pasta 'xicaras'\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras'\n",
        "\n",
        "# Caminho para a pasta de imagens de TREINAMENTO\n",
        "gdrive_image_path = os.path.join(gdrive_base_path, 'train')\n",
        "\n",
        "# Nome do arquivo JSON em formato COCO para as xícaras\n",
        "gdrive_json_filename = 'labels_my-project-name_2025-10-13-12-41-18.json'\n",
        "gdrive_json_path = os.path.join(gdrive_base_path, gdrive_json_filename)\n",
        "\n",
        "# --- Criação das pastas locais no Colab ---\n",
        "base_dir = '/content/yolo_dataset_xicaras'\n",
        "images_train_dir = os.path.join(base_dir, 'images', 'train')\n",
        "labels_train_dir = os.path.join(base_dir, 'labels', 'train')\n",
        "\n",
        "if os.path.exists(base_dir):\n",
        "    shutil.rmtree(base_dir)\n",
        "\n",
        "os.makedirs(images_train_dir, exist_ok=True)\n",
        "os.makedirs(labels_train_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Estrutura de pastas criada em: {base_dir}\")\n",
        "\n",
        "# --- Carregando o arquivo de anotações ---\n",
        "with open(gdrive_json_path, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# --- Processamento das Anotações e Imagens ---\n",
        "images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "class_names = list(categories_info.values())\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(f\"Dataset contém {num_classes} classe(s): {', '.join(class_names)}\")\n",
        "\n",
        "print(\"\\nProcessando anotações e copiando imagens de xícaras...\")\n",
        "for ann in tqdm(coco_data['annotations']):\n",
        "    image_id = ann['image_id']\n",
        "    category_id = ann['category_id']\n",
        "    bbox = ann['bbox']\n",
        "\n",
        "    file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "    # Conversão do formato COCO para YOLO\n",
        "    x_min, y_min, bbox_w, bbox_h = bbox\n",
        "    x_center = (x_min + bbox_w / 2) / img_w\n",
        "    y_center = (y_min + bbox_h / 2) / img_h\n",
        "    norm_w = bbox_w / img_w\n",
        "    norm_h = bbox_h / img_h\n",
        "    yolo_class_id = category_id - 1\n",
        "    yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "\n",
        "    # Salva o arquivo de anotação\n",
        "    label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "    with open(os.path.join(labels_train_dir, label_file_name), 'a') as f:\n",
        "        f.write(yolo_format_str)\n",
        "\n",
        "    # Copia o arquivo de imagem do Google Drive para a pasta local do Colab\n",
        "    source_image_path = os.path.join(gdrive_image_path, file_name)\n",
        "    dest_image_path = os.path.join(images_train_dir, file_name)\n",
        "    if not os.path.exists(dest_image_path):\n",
        "        shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "print(\"\\nPreparação do dataset de xícaras concluída!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBojX-Tsdqy2",
        "outputId": "1de92499-14d7-4def-b722-ba27402c8652"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrutura de pastas criada em: /content/yolo_dataset_xicaras\n",
            "Dataset contém 1 classe(s): xicara\n",
            "\n",
            "Processando anotações e copiando imagens de xícaras...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:00<00:00, 127.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preparação do dataset de xícaras concluída!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando Arquivo de Configuração do Dataset (YAML)"
      ],
      "metadata": {
        "id": "cnAziz_bdxtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Cria o dicionário com as informações do novo dataset\n",
        "yaml_data = {\n",
        "    'train': os.path.join(base_dir, 'images', 'train'),\n",
        "    'val': os.path.join(base_dir, 'images', 'train'), # Usando o mesmo conjunto para validação\n",
        "    'nc': num_classes,\n",
        "    'names': class_names\n",
        "}\n",
        "\n",
        "# Salva o arquivo de configuração com um novo nome\n",
        "yaml_file_path = '/content/dataset_xicaras.yaml'\n",
        "with open(yaml_file_path, 'w') as f:\n",
        "    yaml.dump(yaml_data, f, sort_keys=False)\n",
        "\n",
        "print(f\"Arquivo de configuração '{yaml_file_path}' criado com sucesso:\")\n",
        "!cat {yaml_file_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcUVO5Rhd4i5",
        "outputId": "521031a6-5c06-4703-b39d-905da31e5466"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo de configuração '/content/dataset_xicaras.yaml' criado com sucesso:\n",
            "train: /content/yolo_dataset_xicaras/images/train\n",
            "val: /content/yolo_dataset_xicaras/images/train\n",
            "nc: 1\n",
            "names:\n",
            "- xicara\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iniciando o Treinamento de Modelo - XÍCARAS"
      ],
      "metadata": {
        "id": "QrmweX3ed9Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Carrega um modelo pré-treinado (yolov8n.pt é o menor e mais rápido)\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Inicia o treinamento\n",
        "results = model.train(\n",
        "    data=yaml_file_path,       # Usa o novo arquivo .yaml que criamos\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    project='yolo_training',   # Pasta principal para os resultados\n",
        "    name='xicaras_detector'    # Nome da subpasta específica para este treinamento\n",
        ")\n",
        "\n",
        "print(\"\\nTreinamento de xícaras concluído!\")\n",
        "print(\"Os resultados, incluindo os pesos do modelo treinado, estão na pasta 'yolo_training/xicaras_detector'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8mz-9H3eB6A",
        "outputId": "ec1f064f-580e-4381-afc2-ddf77f1c0d2a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 101.0MB/s 0.1s\n",
            "Ultralytics 8.3.214 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset_xicaras.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=xicaras_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/yolo_training/xicaras_detector, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 25.9MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 114.7MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1617.3±523.5 MB/s, size: 70.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset_xicaras/labels/train... 38 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 38/38 841.2it/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_dataset_xicaras/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 485.4±221.5 MB/s, size: 56.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_xicaras/labels/train.cache... 38 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 38/38 28.5Kit/s 0.0s\n",
            "Plotting labels to /content/yolo_training/xicaras_detector/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolo_training/xicaras_detector\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      1.97G     0.9308      2.545      1.358         18        640: 100% ━━━━━━━━━━━━ 3/3 1.2it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s\n",
            "                   all         38         38    0.00333          1      0.263       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      2.45G      0.935      2.575       1.45         15        640: 100% ━━━━━━━━━━━━ 3/3 3.1it/s 1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.9it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.501      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      2.47G      0.858      2.331      1.367         14        640: 100% ━━━━━━━━━━━━ 3/3 4.0it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.3it/s 0.5s\n",
            "                   all         38         38    0.00333          1      0.829      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      2.47G     0.6108      1.736      1.226         15        640: 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.5it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.903      0.734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      2.49G      0.606      1.541      1.247         11        640: 100% ━━━━━━━━━━━━ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 6.1it/s 0.3s\n",
            "                   all         38         38    0.00333          1      0.849      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      2.49G     0.6725      1.389      1.307         16        640: 100% ━━━━━━━━━━━━ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.808      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      2.52G     0.6141      1.198      1.235         14        640: 100% ━━━━━━━━━━━━ 3/3 5.9it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.8it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.876      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      2.52G     0.6596      1.269      1.249         12        640: 100% ━━━━━━━━━━━━ 3/3 7.4it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.929      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      2.52G     0.5734       1.19      1.188         12        640: 100% ━━━━━━━━━━━━ 3/3 6.1it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38          1      0.405      0.934      0.716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      2.52G     0.6273      1.243       1.22         13        640: 100% ━━━━━━━━━━━━ 3/3 4.4it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.2it/s 0.4s\n",
            "                   all         38         38      0.961      0.651      0.967      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      2.54G     0.6212      1.131      1.182         16        640: 100% ━━━━━━━━━━━━ 3/3 5.8it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38      0.936      0.775      0.965      0.778\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      2.54G     0.6985      1.157       1.27         14        640: 100% ━━━━━━━━━━━━ 3/3 5.4it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.0it/s 0.7s\n",
            "                   all         38         38          1      0.832      0.995      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      2.54G     0.5881      1.114      1.182         18        640: 100% ━━━━━━━━━━━━ 3/3 4.4it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.9it/s 0.7s\n",
            "                   all         38         38      0.993          1      0.995      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      2.55G     0.6117     0.9986      1.193         19        640: 100% ━━━━━━━━━━━━ 3/3 4.9it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.1it/s 0.4s\n",
            "                   all         38         38      0.945      0.974       0.99       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      2.55G     0.8043      1.239      1.376         14        640: 100% ━━━━━━━━━━━━ 3/3 5.8it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38      0.945      0.868      0.984      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      2.55G     0.7403      1.204      1.284         12        640: 100% ━━━━━━━━━━━━ 3/3 7.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.0it/s 0.7s\n",
            "                   all         38         38      0.921      0.919      0.983      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      2.55G     0.5854       0.98      1.188         15        640: 100% ━━━━━━━━━━━━ 3/3 5.1it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.2it/s 0.5s\n",
            "                   all         38         38      0.839      0.895      0.901      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      2.55G     0.5792     0.9946      1.175         14        640: 100% ━━━━━━━━━━━━ 3/3 5.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 6.2it/s 0.3s\n",
            "                   all         38         38       0.69      0.816      0.867      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      2.55G     0.6483       1.06      1.241         12        640: 100% ━━━━━━━━━━━━ 3/3 7.0it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38      0.789      0.868       0.89      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      2.55G     0.5316     0.9002      1.114         17        640: 100% ━━━━━━━━━━━━ 3/3 5.8it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.9it/s 0.3s\n",
            "                   all         38         38       0.93      0.697      0.898       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      2.55G     0.5943      0.873      1.162         15        640: 100% ━━━━━━━━━━━━ 3/3 6.6it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 6.1it/s 0.3s\n",
            "                   all         38         38      0.902      0.729      0.904      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      2.55G     0.6702     0.9348       1.24         14        640: 100% ━━━━━━━━━━━━ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.8it/s 0.5s\n",
            "                   all         38         38      0.887      0.825       0.92      0.583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      2.55G     0.6373      1.109      1.301         10        640: 100% ━━━━━━━━━━━━ 3/3 4.7it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.0it/s 0.7s\n",
            "                   all         38         38      0.894       0.89       0.96      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      2.55G     0.5925     0.9105      1.156         15        640: 100% ━━━━━━━━━━━━ 3/3 4.6it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.8it/s 0.7s\n",
            "                   all         38         38      0.922      0.935      0.974      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      2.57G     0.5599     0.8583      1.125         12        640: 100% ━━━━━━━━━━━━ 3/3 6.0it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 6.7it/s 0.3s\n",
            "                   all         38         38      0.874      0.921      0.955      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      2.57G     0.5106     0.8149      1.129         14        640: 100% ━━━━━━━━━━━━ 3/3 6.3it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38       0.83      0.903      0.934      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      2.57G     0.6345     0.8931      1.153         16        640: 100% ━━━━━━━━━━━━ 3/3 7.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.1it/s 0.4s\n",
            "                   all         38         38      0.899      0.947      0.959      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      2.58G     0.5399      0.866      1.173         13        640: 100% ━━━━━━━━━━━━ 3/3 7.1it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38       0.91      0.921      0.969      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50       2.6G     0.5625     0.8388      1.133         15        640: 100% ━━━━━━━━━━━━ 3/3 7.4it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38       0.91      0.921      0.969      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50       2.6G     0.5511     0.9022      1.168         12        640: 100% ━━━━━━━━━━━━ 3/3 6.1it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.6it/s 0.4s\n",
            "                   all         38         38          1      0.839      0.973      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50       2.6G     0.5227     0.8134      1.109         19        640: 100% ━━━━━━━━━━━━ 3/3 6.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.4it/s 0.4s\n",
            "                   all         38         38      0.901          1      0.984       0.79\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50       2.6G     0.5264     0.7759        1.1         14        640: 100% ━━━━━━━━━━━━ 3/3 6.9it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.4it/s 0.5s\n",
            "                   all         38         38      0.996      0.895      0.985      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      2.62G     0.5009       0.78      1.085         14        640: 100% ━━━━━━━━━━━━ 3/3 7.4it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.5it/s 0.6s\n",
            "                   all         38         38      0.996      0.895      0.985      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      2.62G     0.5259     0.8064      1.107         11        640: 100% ━━━━━━━━━━━━ 3/3 4.6it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.1it/s 0.6s\n",
            "                   all         38         38      0.935      0.947      0.986      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      2.62G     0.6273      0.852      1.197         14        640: 100% ━━━━━━━━━━━━ 3/3 5.9it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.8it/s 0.7s\n",
            "                   all         38         38      0.997      0.974      0.993      0.895\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      2.62G     0.4519     0.8006      1.094         11        640: 100% ━━━━━━━━━━━━ 3/3 6.8it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.0it/s 0.4s\n",
            "                   all         38         38      0.974      0.997      0.994      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      2.62G     0.4986      0.768      1.124         11        640: 100% ━━━━━━━━━━━━ 3/3 7.0it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.4it/s 0.4s\n",
            "                   all         38         38      0.974      0.997      0.994      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      2.62G      0.477     0.7373      1.052         12        640: 100% ━━━━━━━━━━━━ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.4it/s 0.5s\n",
            "                   all         38         38      0.997          1      0.995      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      2.62G      0.523     0.8334      1.127         17        640: 100% ━━━━━━━━━━━━ 3/3 7.3it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.0it/s 0.4s\n",
            "                   all         38         38          1          1      0.995      0.913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      2.62G     0.5623      0.824      1.147         12        640: 100% ━━━━━━━━━━━━ 3/3 7.3it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.6it/s 0.4s\n",
            "                   all         38         38      0.997          1      0.995      0.907\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      2.62G      0.478      1.253       1.14          6        640: 100% ━━━━━━━━━━━━ 3/3 2.4it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.7it/s 0.7s\n",
            "                   all         38         38      0.997          1      0.995      0.907\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      2.62G     0.3543      1.073      1.043          6        640: 100% ━━━━━━━━━━━━ 3/3 6.7it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38      0.998          1      0.995      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      2.62G     0.4654      1.302      1.175          6        640: 100% ━━━━━━━━━━━━ 3/3 5.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.8it/s 0.7s\n",
            "                   all         38         38      0.998          1      0.995      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      2.62G     0.3206     0.9854      1.036          6        640: 100% ━━━━━━━━━━━━ 3/3 4.7it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.8it/s 0.5s\n",
            "                   all         38         38      0.997          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      2.62G     0.3723      1.024       1.03          6        640: 100% ━━━━━━━━━━━━ 3/3 6.9it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.3it/s 0.6s\n",
            "                   all         38         38      0.997          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      2.62G     0.3323     0.9969      1.029          6        640: 100% ━━━━━━━━━━━━ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 7.1it/s 0.3s\n",
            "                   all         38         38      0.997          1      0.995      0.942\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      2.62G     0.3081     0.9614       1.01          6        640: 100% ━━━━━━━━━━━━ 3/3 6.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 6.7it/s 0.3s\n",
            "                   all         38         38      0.999          1      0.995      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      2.62G      0.302     0.9395     0.9774          6        640: 100% ━━━━━━━━━━━━ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.7it/s 0.3s\n",
            "                   all         38         38      0.999          1      0.995      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      2.62G     0.3072      0.945     0.9993          6        640: 100% ━━━━━━━━━━━━ 3/3 6.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 5.0it/s 0.4s\n",
            "                   all         38         38      0.999          1      0.995      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      2.62G      0.313     0.9711     0.9569          6        640: 100% ━━━━━━━━━━━━ 3/3 7.4it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.9it/s 0.4s\n",
            "                   all         38         38      0.999          1      0.995      0.966\n",
            "\n",
            "50 epochs completed in 0.019 hours.\n",
            "Optimizer stripped from /content/yolo_training/xicaras_detector/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/yolo_training/xicaras_detector/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/yolo_training/xicaras_detector/weights/best.pt...\n",
            "Ultralytics 8.3.214 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38      0.999          1      0.995      0.963\n",
            "Speed: 0.3ms preprocess, 2.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolo_training/xicaras_detector\u001b[0m\n",
            "\n",
            "Treinamento de xícaras concluído!\n",
            "Os resultados, incluindo os pesos do modelo treinado, estão na pasta 'yolo_training/xicaras_detector'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo das métricas do Treinamento - 25 Épocas\n",
        "\n",
        "### Box(P) - Precisão (0.971): Quando o modelo diz \"isto é uma xícara\", ele está correto em 97.1% das vezes. Um resultado fantástico, com pouquíssimos alarmes falsos.\n",
        "\n",
        "### Box(R) - Recall (0.887): De todas as xícaras que realmente existiam nas imagens, o modelo conseguiu encontrar 88.7% delas. Também é um número muito alto, mostrando que o modelo raramente deixa passar uma xícara sem detectar.\n",
        "\n",
        "### mAP50 (0.989): Esta é a métrica principal e o resultado é quase perfeito: 98.9%. Isso indica que o modelo é extremamente bom em localizar as xícaras corretamente. A performance é significativamente superior à do modelo de chaves na mesma etapa.\n",
        "\n",
        "### mAP50-95 (0.906): Este é talvez o resultado mais impressionante. Um valor de 90.6% nesta métrica rigorosa é excepcional. Ele nos diz que as caixas delimitadoras que o modelo desenha não estão apenas no lugar certo, mas também estão muito bem ajustadas ao tamanho e formato das xícaras."
      ],
      "metadata": {
        "id": "GiHVV65bjESK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo das métricas do Treinamento - 50 Épocas:\n",
        "\n",
        "### Box(P) - Precisão (0.999): Resultado Praticamente Perfeito. Uma precisão de 99.9% indica que quase todas as detecções que o modelo fez estavam corretas. Ele praticamente não cometeu erros de \"falso positivo\" (identificar um objeto que não era uma xícara). Isso o torna extremamente confiável.\n",
        "\n",
        "### Box(R) - Recall (1): Resultado Perfeito. Um recall de 100% é a pontuação máxima. Significa que, de todas as xícaras que realmente existiam nas 38 imagens, o modelo encontrou TODAS. Ele não deixou nenhuma passar despercebida, o que é um feito fantástico.\n",
        "\n",
        "### mAP50 (0.995): Desempenho de Elite. A métrica principal, que combina precisão e recall, atingiu 99.5%. Este é um resultado de altíssima qualidade, confirmando que o modelo localiza as xícaras com uma precisão quase perfeita.\n",
        "\n",
        "### mAP50-95 (0.963): Excepcional e Robusto. ste é, talvez, o resultado mais impressionante. Um valor de 96.3% nesta métrica, que é muito mais rigorosa, é excepcional. Ele nos diz que as caixas delimitadoras que o modelo desenha não estão apenas no lugar certo, mas também estão muito bem ajustadas ao tamanho e formato das xícaras, mesmo sob critérios de avaliação muito exigentes.\n",
        "\n",
        "# Conclusão:\n",
        "\n",
        "### Este modelo de detecção de xícaras atingiu um nível de desempenho de elite. A combinação de precisão quase perfeita, recall perfeito e um mAP50-95 altíssimo indica que o modelo não apenas aprendeu a identificar xícaras, mas o fez de forma extremamente robusta e precisa.\n",
        "\n",
        "### Diferente do modelo de chaves, que mostrou sinais de overfitting, este modelo parece ter aprendido as características essenciais das xícaras de uma maneira que o torna muito mais generalizável."
      ],
      "metadata": {
        "id": "ZJb82yxoYO4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Validação Dedicada - XÍCARAS"
      ],
      "metadata": {
        "id": "oQgOF1gtmIgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"--- Iniciando o Processo de Validação do Modelo de Xícaras ---\")\n",
        "\n",
        "# --- 1. CONFIGURAÇÃO DOS CAMINHOS ---\n",
        "# Caminho para a pasta de IMAGENS de validação\n",
        "gdrive_val_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/validation'\n",
        "\n",
        "# Caminho para a pasta base onde o JSON de validação está localizado\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras'\n",
        "\n",
        "# Nome do seu arquivo JSON de validação (formato COCO)\n",
        "gdrive_val_json_name = 'labels_my-project-name_2025-10-14-04-17-44.json'\n",
        "gdrive_val_json_path = os.path.join(gdrive_base_path, gdrive_val_json_name)\n",
        "\n",
        "# Caminho para o seu melhor modelo TREINADO de xícaras\n",
        "model_path = '/content/yolo_training/xicaras_detector/weights/best.pt'\n",
        "\n",
        "# --- 2. PREPARAÇÃO DO DATASET DE VALIDAÇÃO ---\n",
        "print(f\"\\n[PASSO 1/3] Preparando o dataset de validação a partir de: {gdrive_val_path}\")\n",
        "\n",
        "base_dir_val = '/content/yolo_dataset_xicaras_validation'\n",
        "images_val_dir = os.path.join(base_dir_val, 'images', 'val')\n",
        "labels_val_dir = os.path.join(base_dir_val, 'labels', 'val')\n",
        "\n",
        "if os.path.exists(base_dir_val):\n",
        "    shutil.rmtree(base_dir_val)\n",
        "os.makedirs(images_val_dir, exist_ok=True)\n",
        "os.makedirs(labels_val_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    print(f\"Carregando anotações de: {gdrive_val_json_path}\")\n",
        "    with open(gdrive_val_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    if 'annotations' not in coco_data or 'images' not in coco_data or 'categories' not in coco_data:\n",
        "        raise ValueError(\"Erro: O arquivo JSON não parece estar no formato COCO.\")\n",
        "\n",
        "    images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "    categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    class_names = list(categories_info.values())\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\"Encontradas {len(coco_data['images'])} imagens e {len(coco_data['annotations'])} anotações no JSON.\")\n",
        "\n",
        "    for ann in tqdm(coco_data['annotations'], desc=\"Processando anotações\"):\n",
        "        if 'category_id' not in ann or 'bbox' not in ann:\n",
        "            continue\n",
        "\n",
        "        image_id = ann['image_id']\n",
        "        file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "        source_image_path = os.path.join(gdrive_val_path, file_name)\n",
        "        dest_image_path = os.path.join(images_val_dir, file_name)\n",
        "        if not os.path.exists(dest_image_path):\n",
        "            shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "        with open(os.path.join(labels_val_dir, label_file_name), 'a') as f:\n",
        "            category_id = ann['category_id']\n",
        "            bbox = ann['bbox']\n",
        "            x_min, y_min, bbox_w, bbox_h = bbox\n",
        "            x_center = (x_min + bbox_w / 2) / img_w\n",
        "            y_center = (y_min + bbox_h / 2) / img_h\n",
        "            norm_w = bbox_w / img_w\n",
        "            norm_h = bbox_h / img_h\n",
        "            yolo_class_id = category_id - 1\n",
        "            yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "            f.write(yolo_format_str)\n",
        "\n",
        "    print(\"Dataset de validação preparado com sucesso.\")\n",
        "\n",
        "    # --- 3. CRIAÇÃO DO ARQUIVO YAML ---\n",
        "    print(\"\\n[PASSO 2/3] Criando arquivo de configuração 'validation_xicaras.yaml'\")\n",
        "    yaml_val_data = {\n",
        "        'train': images_val_dir,\n",
        "        'val': images_val_dir,\n",
        "        'nc': num_classes,\n",
        "        'names': class_names\n",
        "    }\n",
        "    yaml_val_file_path = '/content/validation_xicaras.yaml'\n",
        "    with open(yaml_val_file_path, 'w') as f:\n",
        "        yaml.dump(yaml_val_data, f, sort_keys=False)\n",
        "    !cat {yaml_val_file_path}\n",
        "\n",
        "    # --- 4. EXECUÇÃO DA VALIDAÇÃO ---\n",
        "    print(\"\\n[PASSO 3/3] Executando a validação...\")\n",
        "    model = YOLO(model_path)\n",
        "    validation_results = model.val(data=yaml_val_file_path)\n",
        "    print(\"\\n--- Processo de Validação Concluído ---\")\n",
        "\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(f\"\\nERRO CRÍTICO: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7oCrXy4mLXw",
        "outputId": "d5396f1e-7ced-4727-825f-b3ef2ad94167"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando o Processo de Validação do Modelo de Xícaras ---\n",
            "\n",
            "[PASSO 1/3] Preparando o dataset de validação a partir de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/validation\n",
            "Carregando anotações de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-14-04-17-44.json\n",
            "Encontradas 5 imagens e 5 anotações no JSON.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando anotações: 100%|██████████| 5/5 [00:00<00:00, 313.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset de validação preparado com sucesso.\n",
            "\n",
            "[PASSO 2/3] Criando arquivo de configuração 'validation_xicaras.yaml'\n",
            "train: /content/yolo_dataset_xicaras_validation/images/val\n",
            "val: /content/yolo_dataset_xicaras_validation/images/val\n",
            "nc: 1\n",
            "names:\n",
            "- xicara\n",
            "\n",
            "[PASSO 3/3] Executando a validação...\n",
            "Ultralytics 8.3.214 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1585.7±389.1 MB/s, size: 61.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_xicaras_validation/labels/val... 5 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5/5 1.1Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset_xicaras_validation/labels/val.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all          5          5       0.99          1      0.995      0.596\n",
            "Speed: 0.3ms preprocess, 31.7ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "\n",
            "--- Processo de Validação Concluído ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resumo de Validação Dedicada - XÍCARAS - 25 Épocas\n",
        "\n",
        "### Box(P) - Precisão (0.949): A precisão de 94.9% é excelente. Significa que praticamente todas as detecções que o modelo fez foram corretas.\n",
        "\n",
        "### Box(R) - Recall (1): Este é um resultado perfeito (100%). De todas as xícaras que existiam nas 5 imagens de validação, o modelo encontrou todas.\n",
        "\n",
        "### mAP50 (0.995): A métrica principal é de 99.5%, o que é praticamente a pontuação máxima. Isso confirma que o modelo não só encontra todas as xícaras, mas também as localiza com altíssima precisão.\n",
        "\n",
        "### mAP50-95 (0.551): Este resultado é o único ponto que merece atenção. Houve uma queda em relação ao treino (de 90.6% para 55.1%). O que significa que, embora o modelo encontre todas as xícaras, a \"qualidade\" das caixas delimitadoras (o quão justo o retângulo fica ao redor do objeto) não é tão perfeita nas imagens de validação quanto era nas de treino. No entanto, um valor de 55.1% ainda é considerado bom e funcional."
      ],
      "metadata": {
        "id": "xqA5UFV_mf6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo de Validação Dedicada - XÍCARAS - 50 Épocas\n",
        "\n",
        "### Box(P) - Precisão (0.99): Quase Perfeito. Mede a exatidão das detecções. De todas as vezes que o modelo disse \"isto é uma xícara\", ele estava certo em 99% das vezes. Este é um resultado de elite. Significa que o modelo é extremamente confiável e quase nunca comete erros de \"falso positivo\" (identificar um objeto que não é uma xícara).\n",
        "\n",
        "### Box(R) - Recall (1): Perfeito. Mede a capacidade do modelo de encontrar todos os objetos existentes. Um recall de 100% é a pontuação máxima.O modelo encontrou TODAS as xícaras que existiam nas 5 imagens de validação. Ele não deixou nenhuma passar despercebida, o que é um feito fantástico e o torna muito robusto.\n",
        "\n",
        "### mAP50 (0.995): Desempenho de Elite. A principal métrica, que combina precisão e recall. Uma detecção é considerada correta se a caixa prevista tiver pelo menos 50% de sobreposição com a caixa real. Uma pontuação de 99.5% é o mais próximo da perfeição que se pode esperar. Isso confirma que o modelo localiza as xícaras com uma precisão altíssima.\n",
        "\n",
        "### mAP50-95 (0.596): Bom e Consistente. Uma métrica muito mais rigorosa, que calcula a média da performance em 10 níveis diferentes de exigência (de 50% a 95% de sobreposição). O valor de 59.6% é bom. A queda em relação ao valor do treinamento (que era de 96.3%) é esperada e normal. Isso nos diz que, embora o modelo encontre as xícaras perfeitamente, a delimitação das caixas delimitadoras não é sempre milimétrica em imagens novas, mas ainda assim é muito funcional.\n",
        "\n",
        "# Conclusão:\n",
        "\n",
        "### O modelo de detecção de xícaras é excelente e confiável. O fato de a métrica principal (mAP50) e o recall terem se mantido perfeitos na validação é a melhor prova de que ele não sofreu de overfitting. Ele aprendeu as características essenciais de uma \"xícara\" de forma tão robusta que consegue aplicar esse conhecimento com a mesma eficácia em imagens que nunca viu antes."
      ],
      "metadata": {
        "id": "AKd95YVeZORv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste Modelo - XÍCARA"
      ],
      "metadata": {
        "id": "K9qn9Y10pZPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"--- Iniciando o Processo de Teste Final do Modelo de Xícaras ---\")\n",
        "\n",
        "# --- 1. CONFIGURAÇÃO DOS CAMINHOS ---\n",
        "# Caminho para a pasta de IMAGENS de teste\n",
        "gdrive_test_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/test'\n",
        "\n",
        "# Caminho para a pasta base onde o JSON de teste está localizado\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras'\n",
        "\n",
        "# Nome do seu arquivo JSON de teste (formato COCO)\n",
        "gdrive_test_json_name = 'labels_my-project-name_2025-10-14-04-32-33.json'\n",
        "gdrive_test_json_path = os.path.join(gdrive_base_path, gdrive_test_json_name)\n",
        "\n",
        "# Caminho para o seu melhor modelo TREINADO de xícaras\n",
        "model_path = '/content/yolo_training/xicaras_detector/weights/best.pt'\n",
        "\n",
        "# --- 2. PREPARAÇÃO DO DATASET DE TESTE ---\n",
        "print(f\"\\n[PASSO 1/3] Preparando o dataset de teste a partir de: {gdrive_test_path}\")\n",
        "\n",
        "base_dir_test = '/content/yolo_dataset_xicaras_test'\n",
        "images_test_dir = os.path.join(base_dir_test, 'images', 'test')\n",
        "labels_test_dir = os.path.join(base_dir_test, 'labels', 'test')\n",
        "\n",
        "if os.path.exists(base_dir_test):\n",
        "    shutil.rmtree(base_dir_test)\n",
        "os.makedirs(images_test_dir, exist_ok=True)\n",
        "os.makedirs(labels_test_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    print(f\"Carregando anotações de: {gdrive_test_json_path}\")\n",
        "    with open(gdrive_test_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    if 'annotations' not in coco_data or 'images' not in coco_data or 'categories' not in coco_data:\n",
        "        raise ValueError(\"Erro: O arquivo JSON não parece estar no formato COCO.\")\n",
        "\n",
        "    images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "    categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    class_names = list(categories_info.values())\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\"Encontradas {len(coco_data['images'])} imagens e {len(coco_data['annotations'])} anotações no JSON de teste.\")\n",
        "\n",
        "    for ann in tqdm(coco_data['annotations'], desc=\"Processando anotações de teste\"):\n",
        "        if 'category_id' not in ann or 'bbox' not in ann:\n",
        "            continue\n",
        "\n",
        "        image_id = ann['image_id']\n",
        "        file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "        source_image_path = os.path.join(gdrive_test_path, file_name)\n",
        "        dest_image_path = os.path.join(images_test_dir, file_name)\n",
        "        if not os.path.exists(dest_image_path):\n",
        "            shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "        with open(os.path.join(labels_test_dir, label_file_name), 'a') as f:\n",
        "            category_id = ann['category_id']\n",
        "            bbox = ann['bbox']\n",
        "            x_min, y_min, bbox_w, bbox_h = bbox\n",
        "            x_center = (x_min + bbox_w / 2) / img_w\n",
        "            y_center = (y_min + bbox_h / 2) / img_h\n",
        "            norm_w = bbox_w / img_w\n",
        "            norm_h = bbox_h / img_h\n",
        "            yolo_class_id = category_id - 1\n",
        "            yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "            f.write(yolo_format_str)\n",
        "\n",
        "    print(\"Dataset de teste preparado com sucesso.\")\n",
        "\n",
        "    # --- 3. CRIAÇÃO DO ARQUIVO YAML DE TESTE ---\n",
        "    print(\"\\n[PASSO 2/3] Criando arquivo de configuração 'test_xicaras.yaml'\")\n",
        "    yaml_test_data = {\n",
        "        'train': images_test_dir,\n",
        "        'val': images_test_dir,   # Apontamos 'val' para o nosso conjunto de teste\n",
        "        'nc': num_classes,\n",
        "        'names': class_names\n",
        "    }\n",
        "    yaml_test_file_path = '/content/test_xicaras.yaml'\n",
        "    with open(yaml_test_file_path, 'w') as f:\n",
        "        yaml.dump(yaml_test_data, f, sort_keys=False)\n",
        "    !cat {yaml_test_file_path}\n",
        "\n",
        "    # --- 4. EXECUÇÃO DO TESTE FINAL ---\n",
        "    print(\"\\n[PASSO 3/3] Executando o teste final com o modelo treinado...\")\n",
        "    model = YOLO(model_path)\n",
        "    test_results = model.val(data=yaml_test_file_path)\n",
        "    print(\"\\n--- Processo de Teste Concluído ---\")\n",
        "\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(f\"\\nERRO CRÍTICO: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3H5iyVDpczm",
        "outputId": "25090ebc-0de8-4e34-c6f7-72914adc176f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando o Processo de Teste Final do Modelo de Xícaras ---\n",
            "\n",
            "[PASSO 1/3] Preparando o dataset de teste a partir de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/test\n",
            "Carregando anotações de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-14-04-32-33.json\n",
            "Encontradas 5 imagens e 5 anotações no JSON de teste.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando anotações de teste: 100%|██████████| 5/5 [00:00<00:00, 318.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset de teste preparado com sucesso.\n",
            "\n",
            "[PASSO 2/3] Criando arquivo de configuração 'test_xicaras.yaml'\n",
            "train: /content/yolo_dataset_xicaras_test/images/test\n",
            "val: /content/yolo_dataset_xicaras_test/images/test\n",
            "nc: 1\n",
            "names:\n",
            "- xicara\n",
            "\n",
            "[PASSO 3/3] Executando o teste final com o modelo treinado...\n",
            "Ultralytics 8.3.214 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1926.6±413.2 MB/s, size: 62.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_xicaras_test/labels/test... 5 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5/5 1.2Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset_xicaras_test/labels/test.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 6.1it/s 0.2s\n",
            "                   all          5          5      0.991          1      0.995      0.671\n",
            "Speed: 0.6ms preprocess, 6.5ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "\n",
            "--- Processo de Teste Concluído ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resumo do Teste Final do Modelo - XÍCARAS - 25 Épocas\n",
        "\n",
        "### Box(P) - Precisão (1): Uma precisão de 100% significa que todas as detecções quemodelo fez estavam corretas. Ele não cometeu nenhum erro de \"falso positivo\" (ou seja, nunca identificou um objeto que não era uma xícara). Isso torna o modelo extremamente confiável.\n",
        "\n",
        "### Box(R) - Recall (0.976): Um resultado quase perfeito (97.6%). O modelo encontrou praticamente todas as xícaras que existiam nas imagens de teste. É um desempenho extremamente robusto.\n",
        "\n",
        "### mAP50 (0.995): A métrica geral de desempenho é de 99.5%, o que é o mais próximo da perfeição que se pode esperar. Isso confirma que o modelo é extremamente preciso na localização das xícaras.\n",
        "\n",
        "### mAP50-95 (0.55): Este resultado permaneceu consistente com o da validação (55%). Isso mostra que, embora o modelo encontre os objetos com precisão quase perfeita, a dimensão das caixas delimitadoras é boa, mas não perfeita, o que é um comportamento totalmente normal e aceitável para um modelo de alto desempenho.\n",
        "\n",
        "# Conclusão\n",
        "\n",
        "### O fato de as métricas de teste serem quase idênticas (e em precisão, até melhores) às da validação é a prova definitiva de que o modelo generalizou de forma brilhante. Ele não apenas \"decorou\" as imagens de treino, mas realmente aprendeu as características que definem uma xícara e consegue aplicar esse conhecimento de forma confiável a imagens completamente novas."
      ],
      "metadata": {
        "id": "qRYnwgf2px82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Teste Final do Modelo - XÍCARAS - 50 Épocas\n",
        "\n",
        "### Box(P) - Precisão (0.991): Quase Perfeito.Mede a exatidão das detecções. De todas as vezes que o modelo disse \"isto é uma xícara\", ele estava certo em 99.1% das vezes. Este é um resultado de elite. Significa que o modelo é extremamente confiável e quase nunca comete erros de \"falso positivo\" (identificar um objeto que não é uma xícara).\n",
        "\n",
        "### Mede a capacidade do modelo de encontrar todos os objetos existentes. Um recall de 100% é a pontuação máxima. O modelo encontrou todas as xícaras que existiam nas 5 imagens de teste. Ele não deixou nenhuma passar despercebida, o que é um feito fantástico e o torna muito robusto.\n",
        "\n",
        "\n",
        "### mAP50 (0.995): Desempenho de Elite. A sua principal métrica, que combina precisão e recall. Uma detecção é considerada correta se a caixa prevista tiver pelo menos 50% de sobreposição com a caixa real.Uma pontuação de 99.5% é o mais próximo da perfeição que se pode esperar. Isso confirma que o modelo localiza as xícaras com uma precisão altíssima.\n",
        "\n",
        "\n",
        "### mAP50-95 (0.671): Muito Bom e Consistente. Uma métrica muito mais rigorosa, que calcula a média da performance em 10 níveis diferentes de exigência (de 50% a 95% de sobreposição). O valor de 67.1% é muito bom e, mais importante, é consistente e até melhor que o resultado da validação (que foi 59.6%). Isso mostra que as caixas delimitadoras são bem ajustadas e que o modelo manteve sua qualidade sob critérios mais rigorosos.\n",
        "\n",
        "\n",
        "# Conclusão:\n",
        "\n",
        "### O resultado mais importante aqui é a consistência e a robustez. O fato de as métricas de teste serem praticamente idênticas (ou até melhores) às da validação é a prova definitiva de que o modelo não sofreu de overfitting e generaliza de forma brilhante. Ele não apenas \"decorou\" as imagens de treino; ele realmente \"aprendeu\" o que é uma xícara e consegue aplicar esse conhecimento com a mesma eficácia em imagens completamente novas."
      ],
      "metadata": {
        "id": "L-T8SBBmacao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão Definitiva - Comparativo Chaves x Xícaras\n",
        "\n",
        "\n",
        "## Ao comparar os dois modelos, a conclusão mais importante não é apenas que um é \"melhor\" que o outro, mas por que isso aconteceu:\n",
        "\n",
        "### A qualidade e a variedade dos dados de treinamento são o fator mais determinante para o sucesso de um modelo de visão computacional.\n",
        "\n",
        "### O trabalho demonstrou isso perfeitamente na prática. O modelo de xícaras foi um sucesso porque os dados permitiram que ele generalizasse. O modelo de chaves, apesar de usar a mesma tecnologia e o mesmo processo, teve dificuldades porque seus dados de treino não foram suficientes para prepará-lo para a variedade do mundo real.\n",
        "\n",
        "### Houve sucesso não apenas o treinamento de dois modelos, mas também uma jornada completa de diagnóstico e análise."
      ],
      "metadata": {
        "id": "eSTn-nNubyiH"
      }
    }
  ]
}