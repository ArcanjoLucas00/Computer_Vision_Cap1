{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conex√£o Drive-Git e Clonagem do Repo no Drive\n"
      ],
      "metadata": {
        "id": "NM49gYJk8lz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Monta o Google Drive (necess√°rio para ter acesso √† pasta de destino)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vo4d1ge8APV",
        "outputId": "af847ca2-39ad-4e57-f564-d86e811f4f58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados do Git\n",
        "\n",
        "github_token = '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'\n",
        "github_username = 'ArcanjoLucas00'\n",
        "repo_name = 'Computer_Vision_Cap1'\n",
        "\n",
        "# Caminho para a pasta no Google Drive que precisa ser atualizada\n",
        "drive_folder = '/content/drive/MyDrive/computer_vision_cap1'\n",
        "\n",
        "# 2. Clona a vers√£o mais recente do seu reposit√≥rio do GitHub\n",
        "# O comando 'rm -rf' garante que, se a pasta j√° existir de uma execu√ß√£o anterior,\n",
        "# ela seja removida para clonar uma c√≥pia limpa e nova.\n",
        "!rm -rf /content/{repo_name}\n",
        "!git clone https://{github_username}:{github_token}@github.com/{github_username}/{repo_name}.git\n",
        "\n",
        "# 3. Sincroniza os arquivos do reposit√≥rio clonado PARA a pasta do Google Drive\n",
        "# A origem agora √© a pasta do reposit√≥rio e o destino √© a pasta do Drive.\n",
        "# A op√ß√£o '--delete' remove arquivos do Drive que n√£o existem mais no reposit√≥rio,\n",
        "# tornando a pasta do Drive um espelho exato do seu repo.\n",
        "print(\"\\nIniciando a sincroniza√ß√£o do GitHub para o Google Drive...\")\n",
        "!rsync -av --delete \"/content/{repo_name}/\" \"{drive_folder}/\"\n",
        "print(\"\\nSincroniza√ß√£o conclu√≠da com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h8om_k-Z5jNN",
        "outputId": "393be269-15b9-42ee-f856-96bb1d1f47f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Computer_Vision_Cap1'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 143 (delta 4), reused 118 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (143/143), 4.52 MiB | 36.43 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "\n",
            "Iniciando a sincroniza√ß√£o do GitHub para o Google Drive...\n",
            "sending incremental file list\n",
            "./\n",
            "README.md\n",
            ".git/\n",
            ".git/HEAD\n",
            ".git/config\n",
            ".git/description\n",
            ".git/index\n",
            ".git/packed-refs\n",
            ".git/branches/\n",
            ".git/hooks/\n",
            ".git/hooks/applypatch-msg.sample\n",
            ".git/hooks/commit-msg.sample\n",
            ".git/hooks/fsmonitor-watchman.sample\n",
            ".git/hooks/post-update.sample\n",
            ".git/hooks/pre-applypatch.sample\n",
            ".git/hooks/pre-commit.sample\n",
            ".git/hooks/pre-merge-commit.sample\n",
            ".git/hooks/pre-push.sample\n",
            ".git/hooks/pre-rebase.sample\n",
            ".git/hooks/pre-receive.sample\n",
            ".git/hooks/prepare-commit-msg.sample\n",
            ".git/hooks/push-to-checkout.sample\n",
            ".git/hooks/update.sample\n",
            ".git/info/\n",
            ".git/info/exclude\n",
            ".git/logs/\n",
            ".git/logs/HEAD\n",
            ".git/logs/refs/\n",
            ".git/logs/refs/heads/\n",
            ".git/logs/refs/heads/main\n",
            ".git/logs/refs/remotes/\n",
            ".git/logs/refs/remotes/origin/\n",
            ".git/logs/refs/remotes/origin/HEAD\n",
            ".git/objects/\n",
            ".git/objects/info/\n",
            ".git/objects/pack/\n",
            ".git/objects/pack/pack-868fef907d5f647d077e4d351fbe1ebd8c7c768b.idx\n",
            ".git/objects/pack/pack-868fef907d5f647d077e4d351fbe1ebd8c7c768b.pack\n",
            ".git/refs/\n",
            ".git/refs/heads/\n",
            ".git/refs/heads/main\n",
            ".git/refs/remotes/\n",
            ".git/refs/remotes/origin/\n",
            ".git/refs/remotes/origin/HEAD\n",
            ".git/refs/tags/\n",
            "Computer_Vision_Cap1/\n",
            "Computer_Vision_Cap1/chaves/\n",
            "Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-12-08-37-05.json\n",
            "Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-12-08-37-20.json\n",
            "Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-14-02-45-54.json\n",
            "Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-14-03-27-51.json\n",
            "Computer_Vision_Cap1/chaves/test/\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0003_Layer 60.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0004_Layer 59.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0037_Layer 8.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0038_Layer 5.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0039_Layer 4.jpg\n",
            "Computer_Vision_Cap1/chaves/test/chaves_0040_Layer 3.jpg\n",
            "Computer_Vision_Cap1/chaves/train/\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0005_Layer 58.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0006_Layer 57.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0007_Layer 56.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0008_Layer 55.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0009_Layer 54.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0010_Layer 53.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0011_Layer 52.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0012_Layer 51.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0013_Layer 50.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0014_Layer 49.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0015_Layer 32.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0016_Layer 33.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0017_Layer 30.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0018_Layer 29.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0019_Layer 28.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0020_Layer 27.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0021_Layer 26.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0022_Layer 25.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0023_Layer 24.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0024_Layer 23.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0025_Layer 22.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0026_Layer 21.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0027_Layer 20.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0028_Layer 17.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0029_Layer 16.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0030_Layer 15.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0031_Layer 14.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0032_Layer 13.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0033_Layer 12.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0034_Layer 11.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0035_Layer 10.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0036_Layer 9.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0044_Layer 1.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0045_Layer 45.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0046_Layer 44.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0047_Layer 43.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0048_Layer 41.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0049_Layer 39.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0050_Layer 48.jpg\n",
            "Computer_Vision_Cap1/chaves/train/chaves_0051_Layer 47.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0000_Layer 63.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0001_Layer 62.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0002_Layer 61.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0041_Layer 2.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0042_Layer 35.jpg\n",
            "Computer_Vision_Cap1/chaves/validation/chaves_0043_Layer 34.jpg\n",
            "Computer_Vision_Cap1/xicaras/\n",
            "Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-13-12-41-09.json\n",
            "Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-13-12-41-18.json\n",
            "Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-14-04-17-44.json\n",
            "Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-14-04-32-33.json\n",
            "Computer_Vision_Cap1/xicaras/test/\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0006_Layer 41.jpg\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0009_Layer 38.jpg\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0010_Layer 37.jpg\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0029_Layer 18.jpg\n",
            "Computer_Vision_Cap1/xicaras/test/xicaras_0038_Layer 9.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0000_Layer 47.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0001_Layer 46.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0002_Layer 45.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0003_Layer 44.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0004_Layer 43.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0005_Layer 42.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0007_Layer 40.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0008_Layer 39.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0012_Layer 35.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0014_Layer 33.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0016_Layer 31.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0017_Layer 30.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0018_Layer 29.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0019_Layer 28.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0020_Layer 27.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0021_Layer 26.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0022_Layer 25.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0023_Layer 24.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0024_Layer 23.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0025_Layer 22.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0026_Layer 21.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0028_Layer 19.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0031_Layer 16.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0032_Layer 15.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0033_Layer 14.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0034_Layer 13.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0035_Layer 12.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0036_Layer 11.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0037_Layer 10.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0039_Layer 8.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0040_Layer 7.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0041_Layer 6.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0042_Layer 5.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0043_Layer 4.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0044_Layer 3.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0045_Layer 2.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0046_Layer 1.jpg\n",
            "Computer_Vision_Cap1/xicaras/train/xicaras_0047_Background copy.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0011_Layer 36.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0013_Layer 34.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0015_Layer 32.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0027_Layer 20.jpg\n",
            "Computer_Vision_Cap1/xicaras/validation/xicaras_0030_Layer 17.jpg\n",
            "\n",
            "sent 10,961,531 bytes  received 2,736 bytes  1,289,913.76 bytes/sec\n",
            "total size is 10,948,628  speedup is 1.00\n",
            "\n",
            "Sincroniza√ß√£o conclu√≠da com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 1: Montar o Google Drive e Instalar Depend√™ncias\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Monta o Google Drive no ambiente do Colab\n",
        "# Uma janela de autentica√ß√£o ir√° aparecer para permitir o acesso.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Instala a biblioteca Ultralytics, que cont√©m o YOLOv8.\n",
        "# O '-q' √© para uma instala√ß√£o silenciosa.\n",
        "!pip install ultralytics -q\n",
        "\n",
        "print(\"Drive montado e Ultralytics instalado com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zIiJfQX-ws1",
        "outputId": "8e4a5793-a1a2-4b0e-f339-27ab58f4c2ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDrive montado e Ultralytics instalado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configura√ß√£o dos Caminhos e Prepara√ß√£o do Dataset"
      ],
      "metadata": {
        "id": "8WzXpn4Y-_h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 2: Configura√ß√£o dos Caminhos e Prepara√ß√£o do Dataset (VERS√ÉO FINAL CORRIGIDA)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Defina seus caminhos aqui ---\n",
        "# O caminho para as imagens agora aponta para a subpasta 'train'\n",
        "gdrive_image_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/train'\n",
        "\n",
        "# O caminho para o arquivo JSON permanece na pasta 'chaves'\n",
        "gdrive_json_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-12-08-37-20.json'\n",
        "\n",
        "# --- Cria√ß√£o das pastas locais no Colab ---\n",
        "base_dir = '/content/yolo_dataset'\n",
        "images_train_dir = os.path.join(base_dir, 'images', 'train')\n",
        "labels_train_dir = os.path.join(base_dir, 'labels', 'train')\n",
        "\n",
        "if os.path.exists(base_dir):\n",
        "    shutil.rmtree(base_dir)\n",
        "\n",
        "os.makedirs(images_train_dir, exist_ok=True)\n",
        "os.makedirs(labels_train_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Estrutura de pastas criada em: {base_dir}\")\n",
        "\n",
        "# --- Carregando o arquivo de anota√ß√µes ---\n",
        "with open(gdrive_json_path, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# --- Processamento das Anota√ß√µes e Imagens ---\n",
        "images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "class_names = list(categories_info.values())\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(f\"Dataset cont√©m {num_classes} classe(s): {', '.join(class_names)}\")\n",
        "\n",
        "print(\"\\nProcessando anota√ß√µes e copiando imagens...\")\n",
        "for ann in tqdm(coco_data['annotations']):\n",
        "    image_id = ann['image_id']\n",
        "    category_id = ann['category_id']\n",
        "    bbox = ann['bbox']\n",
        "\n",
        "    file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "    x_min, y_min, bbox_w, bbox_h = bbox\n",
        "    x_center = (x_min + bbox_w / 2) / img_w\n",
        "    y_center = (y_min + bbox_h / 2) / img_h\n",
        "    norm_w = bbox_w / img_w\n",
        "    norm_h = bbox_h / img_h\n",
        "\n",
        "    yolo_class_id = category_id - 1\n",
        "    yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "\n",
        "    label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "\n",
        "    with open(os.path.join(labels_train_dir, label_file_name), 'a') as f:\n",
        "        f.write(yolo_format_str)\n",
        "\n",
        "    # **CORRE√á√ÉO APLICADA AQUI**\n",
        "    # Agora o script busca a imagem na pasta correta ('.../chaves/train/')\n",
        "    source_image_path = os.path.join(gdrive_image_path, file_name)\n",
        "    dest_image_path = os.path.join(images_train_dir, file_name)\n",
        "    if not os.path.exists(dest_image_path):\n",
        "        shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "print(\"\\nPrepara√ß√£o do dataset conclu√≠da!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuGP1Zpa-9Tr",
        "outputId": "8fc322aa-c31e-4db0-ae6c-fe49977fae25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrutura de pastas criada em: /content/yolo_dataset\n",
            "Dataset cont√©m 1 classe(s): chave\n",
            "\n",
            "Processando anota√ß√µes e copiando imagens...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:00<00:00, 204.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prepara√ß√£o do dataset conclu√≠da!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Criando o Arquivo de Configura√ß√£o do Dataset (YAML)"
      ],
      "metadata": {
        "id": "TF2xPSJCArm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# As vari√°veis (base_dir, num_classes, class_names) foram definidas na C√©lula 2\n",
        "# Este c√≥digo as utiliza para criar o arquivo de configura√ß√£o.\n",
        "yaml_data = {\n",
        "    'train': os.path.join(base_dir, 'images', 'train'),\n",
        "    'val': os.path.join(base_dir, 'images', 'train'), # Usando o mesmo conjunto para valida√ß√£o por simplicidade\n",
        "    'nc': num_classes,                               # N√∫mero de classes (neste caso, 1)\n",
        "    'names': class_names                             # Nomes das classes (['chave'])\n",
        "}\n",
        "\n",
        "# Salva o arquivo de configura√ß√£o no diret√≥rio principal do Colab\n",
        "yaml_file_path = '/content/dataset.yaml'\n",
        "with open(yaml_file_path, 'w') as f:\n",
        "    yaml.dump(yaml_data, f, sort_keys=False)\n",
        "\n",
        "print(f\"Arquivo de configura√ß√£o '{yaml_file_path}' criado com sucesso:\")\n",
        "# O comando 'cat' exibe o conte√∫do do arquivo que acabamos de criar\n",
        "!cat {yaml_file_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTNtjCD7BCHX",
        "outputId": "1b136991-57f9-4873-9e66-9f08573b59fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo de configura√ß√£o '/content/dataset.yaml' criado com sucesso:\n",
            "train: /content/yolo_dataset/images/train\n",
            "val: /content/yolo_dataset/images/train\n",
            "nc: 1\n",
            "names:\n",
            "- chave\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicia o Treinamento do YOLOv8 - CHAVES"
      ],
      "metadata": {
        "id": "UtrQevH9BNZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Carrega um modelo pr√©-treinado.\n",
        "# 'yolov8n.pt' √© o menor e mais r√°pido. Outras op√ß√µes: yolov8s, yolov8m, yolov8l, yolov8x\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Inicia o treinamento do modelo\n",
        "# data: Caminho para o arquivo .yaml de configura√ß√£o.\n",
        "# epochs: N√∫mero de vezes que o modelo ver√° o dataset inteiro. Comece com 25-50.\n",
        "# imgsz: Tamanho para o qual as imagens ser√£o redimensionadas para o treinamento. 640 √© um bom padr√£o.\n",
        "results = model.train(\n",
        "    data=yaml_file_path,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    project='/content/drive/MyDrive/YOLO_Models_Trained', # Nome da pasta onde os resultados ser√£o salvos\n",
        "    name='chaves_detector'   # Nome da subpasta espec√≠fica para este treinamento\n",
        ")\n",
        "\n",
        "print(\"\\nTreinamento conclu√≠do!\")\n",
        "print(\"Os resultados, incluindo os pesos do modelo treinado, est√£o na pasta 'yolo_training/chaves_detector'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny6_Ni2sBQnq",
        "outputId": "b806a8be-7ea4-4e13-dedb-d485355a3562"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.214 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset_xicaras.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=chaves_detector2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/YOLO_Models_Trained, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 592.3¬±320.1 MB/s, size: 64.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset_xicaras/labels/train.cache... 38 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 38/38 42.0Kit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 549.1¬±323.4 MB/s, size: 57.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_xicaras/labels/train.cache... 38 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 38/38 26.1Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50         0G      1.048       2.63      1.511         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 33.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.9s\n",
            "                   all         38         38    0.00333          1      0.387      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50         0G     0.9344      2.526      1.472         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38    0.00333          1      0.846       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50         0G     0.6286      2.076       1.28         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38    0.00333          1      0.967      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50         0G     0.6854      1.604       1.26         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38    0.00339          1      0.974      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50         0G     0.5843      1.368       1.18         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.5s\n",
            "                   all         38         38    0.00333          1      0.808      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50         0G     0.6126       1.41      1.258         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 32.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38    0.00333          1       0.68      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50         0G     0.5844      1.192      1.196         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38    0.00333          1      0.866      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50         0G      0.545      1.239      1.132         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.1s\n",
            "                   all         38         38    0.00333          1      0.916      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50         0G     0.5663      1.275      1.162         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.8s\n",
            "                   all         38         38      0.972      0.915      0.969      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50         0G     0.5157      1.093      1.098         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 32.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.8s\n",
            "                   all         38         38       0.96      0.921      0.967      0.584\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50         0G     0.5209      1.078      1.157         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38      0.956      0.567       0.95      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50         0G     0.4591     0.9774      1.037         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38          1      0.553       0.97      0.732\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50         0G     0.7485      1.251      1.308         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38          1      0.989      0.995      0.751\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50         0G     0.5743     0.9739      1.184         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 12.0s\n",
            "                   all         38         38       0.97      0.974      0.982      0.724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50         0G     0.6225      1.092       1.19         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 33.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.6s\n",
            "                   all         38         38      0.949      0.982      0.991      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50         0G     0.5765      1.034       1.14         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38      0.942          1      0.977      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50         0G     0.5928     0.9832       1.17         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.1s\n",
            "                   all         38         38      0.903       0.98      0.968      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50         0G     0.5998      1.041       1.18         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.9s\n",
            "                   all         38         38      0.935          1      0.991      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50         0G     0.6098      1.008      1.212         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.8s\n",
            "                   all         38         38      0.974      0.985      0.994      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50         0G     0.5767     0.9121      1.151         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 32.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.4s\n",
            "                   all         38         38      0.966      0.947      0.988       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50         0G     0.6013     0.9101      1.193         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.8s\n",
            "                   all         38         38      0.923      0.948      0.982      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50         0G     0.6174      1.055      1.228         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.1s\n",
            "                   all         38         38      0.926      0.992      0.977      0.764\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50         0G     0.5808     0.8921      1.165         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38      0.943      0.974      0.987      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50         0G     0.5628     0.9397      1.195         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.5s\n",
            "                   all         38         38      0.991      0.974      0.994      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50         0G     0.5805     0.8538      1.128         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38      0.973      0.961      0.982       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50         0G     0.6151     0.8979      1.193         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 32.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38      0.944          1      0.984      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50         0G     0.5381     0.8009      1.106         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38      0.925      0.974       0.98      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50         0G     0.5113     0.8248      1.129         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.1it/s 14.1s\n",
            "                   all         38         38      0.951      0.921      0.985      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50         0G     0.9009      1.199      1.468         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.0s\n",
            "                   all         38         38      0.951      0.921      0.985      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50         0G     0.6968      1.044      1.267          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.9s\n",
            "                   all         38         38          1      0.999      0.995      0.821\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50         0G     0.5576     0.7937      1.102         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.4s\n",
            "                   all         38         38      0.974      0.994      0.994      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50         0G     0.6064     0.8772       1.19         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.0s\n",
            "                   all         38         38       0.97          1      0.994      0.826\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50         0G     0.4806     0.7763      1.051         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38       0.97          1      0.994      0.826\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50         0G     0.5195     0.8034      1.156         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38       0.97          1      0.994      0.814\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50         0G     0.5067     0.8011      1.125         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38      0.969          1      0.994      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50         0G     0.6201     0.9081      1.222         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38      0.994          1      0.995       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50         0G      0.529     0.7624      1.079         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 12.7s\n",
            "                   all         38         38      0.994          1      0.995       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50         0G     0.4779     0.7505      1.044         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 29.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.6s\n",
            "                   all         38         38      0.996          1      0.995      0.904\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50         0G      0.441     0.7505      1.038         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38      0.998          1      0.995      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50         0G     0.5067     0.7414      1.082         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 32.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.7s\n",
            "                   all         38         38      0.998          1      0.995      0.902\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50         0G     0.3472       1.19      1.005          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.8s\n",
            "                   all         38         38      0.998          1      0.995      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50         0G     0.3951       1.16      1.166          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38      0.998          1      0.995      0.915\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50         0G     0.3344      1.038     0.9934          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38      0.997          1      0.995      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50         0G     0.4144      1.239      1.153          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 31.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.3s\n",
            "                   all         38         38      0.998          1      0.995      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50         0G      0.381       1.12      1.099          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 32.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 10.6s\n",
            "                   all         38         38      0.998          1      0.995      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50         0G     0.2994     0.9823     0.9791          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.2s\n",
            "                   all         38         38      0.998          1      0.995      0.936\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50         0G     0.3103     0.9902     0.9947          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.0s\n",
            "                   all         38         38      0.998          1      0.995      0.957\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50         0G      0.276     0.9086     0.9067          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.0s\n",
            "                   all         38         38      0.998          1      0.995      0.974\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50         0G      0.284     0.9213     0.9377          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 32.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.9s\n",
            "                   all         38         38      0.998          1      0.995      0.974\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50         0G     0.3104     0.9198      1.004          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 0.1it/s 29.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 12.0s\n",
            "                   all         38         38      0.998          1      0.995      0.977\n",
            "\n",
            "50 epochs completed in 0.596 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2/weights/best.pt...\n",
            "Ultralytics 8.3.214 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 0.2it/s 11.1s\n",
            "                   all         38         38      0.998          1      0.995      0.977\n",
            "Speed: 3.0ms preprocess, 256.1ms inference, 0.0ms loss, 21.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/YOLO_Models_Trained/chaves_detector2\u001b[0m\n",
            "\n",
            "Treinamento conclu√≠do!\n",
            "Os resultados, incluindo os pesos do modelo treinado, est√£o na pasta 'yolo_training/chaves_detector'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Treino - Chaves - 25 √âpocas\n",
        "\n",
        "### mAP50(0.97) - Esta √© a m√©trica principal para detec√ß√£o de objetos. Um valor de 97% √© excelente. Ele mede a precis√£o do modelo em acertar a localiza√ß√£o das \"chaves\". Simplificando, o modelo est√° acertando quase sempre.\n",
        "\n",
        "\n",
        "### mAP50-95(0.866) - Esta √© uma m√©trica mais rigorosa, que mede a precis√£o em diferentes n√≠veis de exig√™ncia de sobreposi√ß√£o. Um valor de 86.6% aqui √© muito forte e indica que as caixas delimitadoras (os ret√¢ngulos) que o modelo desenha est√£o bem justas aos objetos."
      ],
      "metadata": {
        "id": "HBHrnwmHG-4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Treino - Chaves - 50 √âpocas\n",
        "\n",
        "### Box(P) - Precis√£o (0.998): Resultado Praticamente Perfeito. Uma precis√£o de 99.8% indica que quase todas as detec√ß√µes que o modelo fez estavam corretas. Ele praticamente n√£o cometeu erros de \"falso positivo\" (identificar um objeto que n√£o era uma chave). Isso o torna extremamente confi√°vel.\n",
        "\n",
        "### Box(R) - Recall (1): Resultado Perfeito. Um recall de 100% √© a pontua√ß√£o m√°xima. Significa que, de todas as chaves que realmente existiam nas 38 imagens, o modelo encontrou todas. N√£o deixou nenhuma passar despercebida, o que √© um feito fant√°stico.\n",
        "\n",
        "### mAP50 (0.995): Desempenho de Elite. A m√©trica principal, que combina precis√£o e recall, atingiu 99.5%. Este √© um resultado de alt√≠ssima qualidade, confirmando que o modelo localiza as chaves com uma precis√£o quase perfeita.\n",
        "\n",
        "### mAP50-95 (0.977): Excepcional e Robusto. Este √©, talvez, o resultado mais impressionante. Um valor de 97.7% nesta m√©trica, que √© muito mais rigorosa, √© excepcional. Ele nos diz que as caixas delimitadoras que o modelo desenha n√£o est√£o apenas no lugar certo, mas tamb√©m est√£o muito bem ajustadas ao tamanho e formato das chaves, mesmo sob crit√©rios de avalia√ß√£o muito exigentes.\n"
      ],
      "metadata": {
        "id": "9fa2INmdUJb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√©lula para Valida√ß√£o Dedicada - CHAVES"
      ],
      "metadata": {
        "id": "7LDWIMPyIXaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA DE VALIDA√á√ÉO FINAL\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"--- Iniciando o Processo de Valida√ß√£o com Dataset Dedicado ---\")\n",
        "\n",
        "# --- 1. CONFIGURA√á√ÉO DOS CAMINHOS ---\n",
        "gdrive_val_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/validation'\n",
        "\n",
        "# Nome do seu novo arquivo COCO JSON correto\n",
        "gdrive_val_json_name = 'labels_my-project-name_2025-10-14-02-45-54.json'\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves'\n",
        "gdrive_val_json_path = os.path.join(gdrive_base_path, gdrive_val_json_name)\n",
        "\n",
        "model_path = '/content/yolo_training/chaves_detector/weights/best.pt'\n",
        "\n",
        "# --- 2. PREPARA√á√ÉO DO DATASET DE VALIDA√á√ÉO ---\n",
        "print(f\"\\n[PASSO 1/3] Preparando o dataset a partir de: {gdrive_val_path}\")\n",
        "\n",
        "base_dir_val = '/content/yolo_dataset_validation'\n",
        "images_val_dir = os.path.join(base_dir_val, 'images', 'val')\n",
        "labels_val_dir = os.path.join(base_dir_val, 'labels', 'val')\n",
        "\n",
        "if os.path.exists(base_dir_val): shutil.rmtree(base_dir_val)\n",
        "os.makedirs(images_val_dir, exist_ok=True)\n",
        "os.makedirs(labels_val_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    print(f\"Carregando anota√ß√µes de: {gdrive_val_json_path}\")\n",
        "    with open(gdrive_val_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    if 'annotations' not in coco_data or 'images' not in coco_data or 'categories' not in coco_data:\n",
        "        raise ValueError(\"Erro: O arquivo JSON n√£o parece estar no formato COCO.\")\n",
        "\n",
        "    images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "    categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    class_names = list(categories_info.values())\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\"Encontradas {len(coco_data['images'])} imagens e {len(coco_data['annotations'])} anota√ß√µes no JSON.\")\n",
        "\n",
        "    valid_annotations_found = 0\n",
        "    for ann in tqdm(coco_data['annotations'], desc=\"Processando anota√ß√µes\"):\n",
        "        if 'category_id' not in ann or 'bbox' not in ann:\n",
        "            continue\n",
        "\n",
        "        valid_annotations_found += 1\n",
        "        image_id = ann['image_id']\n",
        "        file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "        source_image_path = os.path.join(gdrive_val_path, file_name)\n",
        "        dest_image_path = os.path.join(images_val_dir, file_name)\n",
        "        if not os.path.exists(dest_image_path):\n",
        "            try:\n",
        "                shutil.copy(source_image_path, dest_image_path)\n",
        "            except FileNotFoundError:\n",
        "                print(f\"\\nAviso: A imagem '{file_name}' n√£o foi encontrada em '{gdrive_val_path}' e ser√° ignorada.\")\n",
        "                continue\n",
        "\n",
        "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "        with open(os.path.join(labels_val_dir, label_file_name), 'a') as f:\n",
        "            category_id = ann['category_id']\n",
        "            bbox = ann['bbox']\n",
        "            x_min, y_min, bbox_w, bbox_h = bbox\n",
        "            x_center = (x_min + bbox_w / 2) / img_w\n",
        "            y_center = (y_min + bbox_h / 2) / img_h\n",
        "            norm_w = bbox_w / img_w\n",
        "            norm_h = bbox_h / img_h\n",
        "            yolo_class_id = category_id - 1\n",
        "            yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "            f.write(yolo_format_str)\n",
        "\n",
        "    if valid_annotations_found == 0:\n",
        "        raise ValueError(\"Nenhuma anota√ß√£o v√°lida foi encontrada. Por favor, re-exporte no formato COCO.\")\n",
        "\n",
        "    print(\"Dataset de valida√ß√£o preparado com sucesso.\")\n",
        "\n",
        "    # --- 3. CRIA√á√ÉO DO ARQUIVO YAML ---\n",
        "    print(\"\\n[PASSO 2/3] Criando arquivo de configura√ß√£o 'validation.yaml'\")\n",
        "    yaml_val_data = {\n",
        "        'train': images_val_dir,\n",
        "        'val': images_val_dir,\n",
        "        'nc': num_classes,\n",
        "        'names': class_names\n",
        "    }\n",
        "    yaml_val_file_path = '/content/validation.yaml'\n",
        "    with open(yaml_val_file_path, 'w') as f: yaml.dump(yaml_val_data, f, sort_keys=False)\n",
        "    !cat {yaml_val_file_path}\n",
        "\n",
        "    # --- 4. EXECU√á√ÉO DA VALIDA√á√ÉO ---\n",
        "    print(\"\\n[PASSO 3/3] Executando a valida√ß√£o...\")\n",
        "    model = YOLO(model_path)\n",
        "    validation_results = model.val(data=yaml_val_file_path)\n",
        "    print(\"\\n--- Processo de Valida√ß√£o Conclu√≠do ---\")\n",
        "\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(f\"\\nERRO CR√çTICO: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "91_3QoBrIZfj",
        "outputId": "a3928f51-35db-4068-f138-d0b0c0958449"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando o Processo de Valida√ß√£o com Dataset Dedicado ---\n",
            "\n",
            "[PASSO 1/3] Preparando o dataset a partir de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/validation\n",
            "Carregando anota√ß√µes de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-14-02-45-54.json\n",
            "Encontradas 6 imagens e 6 anota√ß√µes no JSON.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando anota√ß√µes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 169.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset de valida√ß√£o preparado com sucesso.\n",
            "\n",
            "[PASSO 2/3] Criando arquivo de configura√ß√£o 'validation.yaml'\n",
            "train: /content/yolo_dataset_validation/images/val\n",
            "val: /content/yolo_dataset_validation/images/val\n",
            "nc: 1\n",
            "names:\n",
            "- chave\n",
            "\n",
            "[PASSO 3/3] Executando a valida√ß√£o...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.214 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 681.7¬±196.5 MB/s, size: 50.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_validation/labels/val... 6 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 938.0it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset_validation/labels/val.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 0.5it/s 1.9s\n",
            "                   all          6          6       0.79      0.635      0.533      0.112\n",
            "Speed: 2.3ms preprocess, 284.7ms inference, 0.0ms loss, 16.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val5\u001b[0m\n",
            "\n",
            "--- Processo de Valida√ß√£o Conclu√≠do ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo da Valida√ß√£o Dedicada - 25 √âpocas:\n",
        "\n",
        "### Box(P) - precis√£o (0.79): Das vezes que o modelo disse \"isto √© uma chave\", ele estava certo em 79% das vezes. As outras 21% foram \"falsos positivos\" (ele detectou algo que n√£o era uma chave, ou detectou a mesma chave mais de uma vez). Este √© um bom n√∫mero.\n",
        "\n",
        "### Box(R) - Recall(0.635): De todas as chaves que realmente existiam nas 6 imagens, o modelo conseguiu encontrar 63.5% delas. Os 36.5% restantes s√£o \"falsos negativos\" (chaves que estavam na imagem, mas que o modelo n√£o detectou).\n",
        "\n",
        "### mAP50(0.533):  Esta √© a m√©trica principal. Ela representa a \"M√©dia da Precis√£o M√©dia\" com um limiar de acerto de 50%. Simplificando, √© uma nota geral que equilibra a precis√£o e o recall. Um resultado de 53.3% √© um ponto de partida razo√°vel. Ele nos diz que o modelo aprendeu o conceito de \"chave\", mas ainda n√£o √© um especialista e comete erros ao ser exposto a imagens novas.\n",
        "\n",
        "### mAP50-95(0.112): Esta √© uma m√©trica muito mais rigorosa, que calcula a m√©dia do mAP em diferentes n√≠veis de exig√™ncia (de 50% at√© 95%). O valor baixo de 11.2% indica que, embora o modelo consiga encontrar a chave, as caixas delimitadoras (os ret√¢ngulos) que ele desenha muitas vezes n√£o est√£o perfeitamente alinhadas com o objeto real."
      ],
      "metadata": {
        "id": "Q0mmP5DNXQlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo da Valida√ß√£o Dedicada - 50 √âpocas:\n",
        "\n",
        "### Box(P) - Precis√£o (0.79): De todas as vezes que o modelo disse \"isto √© uma chave\", ele estava certo em 79% das vezes. Este √© um bom resultado. Significa que o modelo tem uma alta confian√ßa e raramente comete erros de \"falso positivo\" (identificar algo que n√£o √© uma chave).\n",
        "\n",
        "### Box(R) - Recall (0.635):De todas as chaves que realmente existiam nas imagens, o modelo conseguiu encontrar 63.5% delas.Este resultado √© moderado. Significa que o modelo deixou de detectar cerca de 36.5% das chaves que estavam presentes (falsos negativos). Ele √© bom em acertar quando detecta, mas n√£o √© t√£o bom em encontrar todos os objetos.\n",
        "\n",
        "### mAP50 (0.533): Esta √© a m√©trica principal (M√©dia da Precis√£o M√©dia) √© a nota geral que equilibra a precis√£o e o recall. O \"50\" significa que uma detec√ß√£o √© considerada \"correta\" se a caixa desenhada pelo modelo tiver pelo menos 50% de sobreposi√ß√£o com a caixa real. Uma pontua√ß√£o de 53.3% indica que o modelo √© um prot√≥tipo funcional. Ele claramente aprendeu o que √© uma chave, mas ainda n√£o √© um especialista. Ele comete erros e tem espa√ßo significativo para melhorar.\n",
        "\n",
        "### mAP50-95 (0.112):Esta √© uma m√©trica muito mais rigorosa. Ela calcula a m√©dia do mAP em 10 n√≠veis diferentes de exig√™ncia (de 50% a 95% de sobreposi√ß√£o). O valor baixo de 11.2% nos diz que as caixas delimitadoras que o modelo desenha n√£o s√£o muito precisas. Elas s√£o boas o suficiente para passar no teste de 50% (por isso o mAP50 √© 0.533), mas falham nos testes mais rigorosos."
      ],
      "metadata": {
        "id": "3mjtWbXbVMdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste: Modelo do Conjunto de Dados de Teste - CHAVES"
      ],
      "metadata": {
        "id": "aWl3Gkf9asGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA DE TESTE FINAL (com o caminho do modelo corrigido)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"--- Iniciando o Processo de Teste Final do Modelo ---\")\n",
        "\n",
        "# --- 1. CONFIGURA√á√ÉO DOS CAMINHOS ---\n",
        "gdrive_test_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/test'\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves'\n",
        "gdrive_test_json_name = 'labels_my-project-name_2025-10-14-03-27-51.json'\n",
        "gdrive_test_json_path = os.path.join(gdrive_base_path, gdrive_test_json_name)\n",
        "\n",
        "# **CORRE√á√ÉO APLICADA AQUI: Apontando para a pasta correta no Drive**\n",
        "model_path = '/content/drive/MyDrive/YOLO_Models_Trained/chaves_detector/weights/best.pt'\n",
        "\n",
        "# --- 2. PREPARA√á√ÉO DO DATASET DE TESTE ---\n",
        "print(f\"\\n[PASSO 1/3] Preparando o dataset de teste a partir de: {gdrive_test_path}\")\n",
        "\n",
        "base_dir_test = '/content/yolo_dataset_test'\n",
        "images_test_dir = os.path.join(base_dir_test, 'images', 'test')\n",
        "labels_test_dir = os.path.join(base_dir_test, 'labels', 'test')\n",
        "\n",
        "if os.path.exists(base_dir_test): shutil.rmtree(base_dir_test)\n",
        "os.makedirs(images_test_dir, exist_ok=True)\n",
        "os.makedirs(labels_test_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    print(f\"Carregando anota√ß√µes de: {gdrive_test_json_path}\")\n",
        "    with open(gdrive_test_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    if 'annotations' not in coco_data or 'images' not in coco_data or 'categories' not in coco_data:\n",
        "        raise ValueError(\"Erro: O arquivo JSON n√£o parece estar no formato COCO.\")\n",
        "\n",
        "    images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "    categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    class_names = list(categories_info.values())\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\"Encontradas {len(coco_data['images'])} imagens e {len(coco_data['annotations'])} anota√ß√µes no JSON de teste.\")\n",
        "\n",
        "    for ann in tqdm(coco_data['annotations'], desc=\"Processando anota√ß√µes de teste\"):\n",
        "        if 'category_id' not in ann or 'bbox' not in ann: continue\n",
        "        image_id = ann['image_id']\n",
        "        file_name, img_w, img_h = images_info[image_id]\n",
        "        source_image_path = os.path.join(gdrive_test_path, file_name)\n",
        "        dest_image_path = os.path.join(images_test_dir, file_name)\n",
        "        if not os.path.exists(dest_image_path):\n",
        "            try: shutil.copy(source_image_path, dest_image_path)\n",
        "            except FileNotFoundError: continue\n",
        "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "        with open(os.path.join(labels_test_dir, label_file_name), 'a') as f:\n",
        "            category_id = ann['category_id']; bbox = ann['bbox']\n",
        "            x_min, y_min, bbox_w, bbox_h = bbox\n",
        "            x_center = (x_min + bbox_w / 2) / img_w; y_center = (y_min + bbox_h / 2) / img_h\n",
        "            norm_w = bbox_w / img_w; norm_h = bbox_h / img_h\n",
        "            yolo_class_id = category_id - 1\n",
        "            yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "            f.write(yolo_format_str)\n",
        "    print(\"Dataset de teste preparado com sucesso.\")\n",
        "\n",
        "    # --- 3. CRIA√á√ÉO DO ARQUIVO YAML ---\n",
        "    print(\"\\n[PASSO 2/3] Criando arquivo de configura√ß√£o 'test.yaml'\")\n",
        "    yaml_test_data = {'train': images_test_dir, 'val': images_test_dir, 'nc': num_classes, 'names': class_names}\n",
        "    yaml_test_file_path = '/content/test.yaml'\n",
        "    with open(yaml_test_file_path, 'w') as f: yaml.dump(yaml_test_data, f, sort_keys=False)\n",
        "    !cat {yaml_test_file_path}\n",
        "\n",
        "    # --- 4. EXECU√á√ÉO DO TESTE FINAL ---\n",
        "    print(\"\\n[PASSO 3/3] Executando o teste final com o modelo treinado...\")\n",
        "    model = YOLO(model_path)\n",
        "    test_results = model.val(data=yaml_test_file_path)\n",
        "    print(\"\\n--- Processo de Teste Conclu√≠do ---\")\n",
        "\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(f\"\\nERRO CR√çTICO: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nTyNRj3ya11_",
        "outputId": "803d3beb-8f81-4276-b074-a3f0fb2c542f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando o Processo de Teste Final do Modelo ---\n",
            "\n",
            "[PASSO 1/3] Preparando o dataset de teste a partir de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/test\n",
            "Carregando anota√ß√µes de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/chaves/labels_my-project-name_2025-10-14-03-27-51.json\n",
            "Encontradas 6 imagens e 6 anota√ß√µes no JSON de teste.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando anota√ß√µes de teste: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 173.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset de teste preparado com sucesso.\n",
            "\n",
            "[PASSO 2/3] Criando arquivo de configura√ß√£o 'test.yaml'\n",
            "train: /content/yolo_dataset_test/images/test\n",
            "val: /content/yolo_dataset_test/images/test\n",
            "nc: 1\n",
            "names:\n",
            "- chave\n",
            "\n",
            "[PASSO 3/3] Executando o teste final com o modelo treinado...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.214 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 892.8¬±141.6 MB/s, size: 56.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_test/labels/test... 6 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 667.0it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset_test/labels/test.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 0.7it/s 1.4s\n",
            "                   all          6          6      0.564      0.441      0.534      0.157\n",
            "Speed: 3.2ms preprocess, 208.4ms inference, 0.0ms loss, 15.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val6\u001b[0m\n",
            "\n",
            "--- Processo de Teste Conclu√≠do ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Teste Final - 25 √âpocas\n",
        "\n",
        "\n",
        "### Box(P) - Precis√£o (0.564): A precis√£o de 56.4% √© um resultado modesto. Significa que, quando o modelo detectou uma \"chave\" nas imagens de teste, ele estava correto em pouco mais da metade das vezes. Os outros ~44% foram detec√ß√µes incorretas (falsos positivos).\n",
        "\n",
        "### Box(R) - Recall (0.441): O recall de 44.1% indica que o modelo conseguiu encontrar menos da metade de todas as chaves que realmente existiam nas imagens de teste. Ele deixou passar um n√∫mero significativo de objetos (falsos negativos).\n",
        "\n",
        "### mAP50 (0.534): Esta √© a sua m√©trica principal e a \"nota final\" do modelo. Um resultado de 53.4% mostra que o modelo tem uma capacidade b√°sica de identificar chaves, mas seu desempenho cai consideravelmente quando exposto a dados completamente novos, indicando que ele n√£o √© muito robusto.\n",
        "\n",
        "### mAP50-95 (0.157): A baixa pontua√ß√£o de 15.7% nesta m√©trica mais rigorosa confirma que as detec√ß√µes que o modelo acertou n√£o foram muito precisas em termos de localiza√ß√£o (as caixas delimitadoras n√£o estavam bem ajustadas).\n",
        "\n",
        "\n",
        "### Considera√ß√µes: Fazendo uma an√°lise das imagens utilizadas em todas as etapas, foi constatado que as imagens utilizadas para o teste, possuiam um modelo de chave pouco visto pelo modelo nas etapas anteriores. Apesar de ainda haver reconhecimento, pode ter influenciado para um reconhecimento mais dificultoso, uma vez que n√£o houveram tantos modelos parecidos para treino e valida√ß√£o.\n",
        "\n",
        "### A conclus√£o mais importante aqui √© a grande diferen√ßa entre o desempenho do modelo nos dados de treino (~97%) e nos dados de teste (53%). Este fen√¥meno √© chamado de overfitting (sobreadapta√ß√£o).Significa que modelo \"decorou\" muito bem as imagens de treino, mas n√£o aprendeu a \"generalizar\" o conceito de \"chave\" de forma eficaz. Quando ele v√™ imagens novas e um pouco diferentes no conjunto de teste, ele tem dificuldade em aplicar o que aprendeu.\n",
        "\n",
        "# Conclus√£o\n",
        "\n",
        "## Aumentar o Dataset √© a solu√ß√£o mais importante para combater o overffiting. O modelo precisa de muito mais exemplos de chaves em √¢ngulos diferentes, com ilumina√ß√µes diferentes, fundos variados e tipos distintos;\n",
        "\n",
        "## Podemos usar Data Augmentation e tamb√©m, revisar a qualidade das anota√ß√µes."
      ],
      "metadata": {
        "id": "YIvAtNMVbh_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Teste Final - 50 √âpocas:\n",
        "\n",
        "### Box(P) - Precis√£o (0.564): Mede a exatid√£o das detec√ß√µes. De todas as vezes que o modelo disse \"isto √© uma chave\", ele estava certo em 56.4% das vezes. √â um resultado moderado. Isso significa que para cada detec√ß√£o correta, h√° quase uma detec√ß√£o incorreta (falso positivo). O modelo ainda est√° um pouco \"confuso\".\n",
        "\n",
        "### Box(R) - Recall (0.441): Mede a capacidade do modelo de encontrar todos os objetos existentes. De todas as chaves que realmente estavam nas imagens, o modelo conseguiu encontrar apenas 44.1%.Este resultado √© um ponto cr√≠tico. Significa que o modelo deixou de detectar mais da metade das chaves que estavam presentes (falsos negativos). Em muitas aplica√ß√µes, um recall baixo pode ser um problema maior que uma precis√£o baixa.\n",
        "\n",
        "### mAP50 (0.534): √â a m√©trica principal, que representa a nota geral do modelo, equilibrando precis√£o e recall. O \"50\" indica que uma detec√ß√£o √© considerada um acerto se a caixa prevista tiver pelo menos 50% de sobreposi√ß√£o com a caixa real. Uma pontua√ß√£o de 53.4% classifica o modelo como um prot√≥tipo funcional. Ele aprendeu o conceito b√°sico de \"chave\", mas ainda n√£o √© robusto o suficiente para ser considerado confi√°vel, pois seu desempenho cai significativamente em dados novos.\n",
        "\n",
        "### mAP50-95 (0.157): Uma m√©trica muito mais rigorosa que mede o desempenho em n√≠veis de exig√™ncia de sobreposi√ß√£o de 50% at√© 95%.O valor baixo de 15.7% confirma que as poucas detec√ß√µes corretas que o modelo fez geralmente n√£o estavam bem ajustadas ao objeto. As caixas delimitadoras estavam um pouco \"frouxas\".\n",
        "\n",
        "# Conclus√£o:\n",
        "\n",
        "### O modelo \"decorou\" muito bem as imagens de treino, mas n√£o aprendeu a generalizar esse conhecimento de forma eficaz para novas imagens. Ele funciona, mas ainda n√£o √© confi√°vel. O resultado, no entanto, √© um excelente diagn√≥stico que aponta o caminho para melhorias, como aumentar significativamente a variedade e a quantidade de imagens de treino.\n"
      ],
      "metadata": {
        "id": "8VEFfNIvWKWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configura√ß√£o dos Caminhos e Prepara√ß√£o de Dados para o Dataset - X√çCARAS"
      ],
      "metadata": {
        "id": "RBkytZYbdmJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 2: Configura√ß√£o dos Caminhos e Prepara√ß√£o do Dataset de X√çCARAS\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Defini√ß√£o dos novos caminhos para o dataset de x√≠caras ---\n",
        "# Caminho base para a pasta 'xicaras'\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras'\n",
        "\n",
        "# Caminho para a pasta de imagens de TREINAMENTO\n",
        "gdrive_image_path = os.path.join(gdrive_base_path, 'train')\n",
        "\n",
        "# Nome do arquivo JSON em formato COCO para as x√≠caras\n",
        "gdrive_json_filename = 'labels_my-project-name_2025-10-13-12-41-18.json'\n",
        "gdrive_json_path = os.path.join(gdrive_base_path, gdrive_json_filename)\n",
        "\n",
        "# --- Cria√ß√£o das pastas locais no Colab ---\n",
        "base_dir = '/content/yolo_dataset_xicaras'\n",
        "images_train_dir = os.path.join(base_dir, 'images', 'train')\n",
        "labels_train_dir = os.path.join(base_dir, 'labels', 'train')\n",
        "\n",
        "if os.path.exists(base_dir):\n",
        "    shutil.rmtree(base_dir)\n",
        "\n",
        "os.makedirs(images_train_dir, exist_ok=True)\n",
        "os.makedirs(labels_train_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Estrutura de pastas criada em: {base_dir}\")\n",
        "\n",
        "# --- Carregando o arquivo de anota√ß√µes ---\n",
        "with open(gdrive_json_path, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# --- Processamento das Anota√ß√µes e Imagens ---\n",
        "images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "class_names = list(categories_info.values())\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(f\"Dataset cont√©m {num_classes} classe(s): {', '.join(class_names)}\")\n",
        "\n",
        "print(\"\\nProcessando anota√ß√µes e copiando imagens de x√≠caras...\")\n",
        "for ann in tqdm(coco_data['annotations']):\n",
        "    image_id = ann['image_id']\n",
        "    category_id = ann['category_id']\n",
        "    bbox = ann['bbox']\n",
        "\n",
        "    file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "    # Convers√£o do formato COCO para YOLO\n",
        "    x_min, y_min, bbox_w, bbox_h = bbox\n",
        "    x_center = (x_min + bbox_w / 2) / img_w\n",
        "    y_center = (y_min + bbox_h / 2) / img_h\n",
        "    norm_w = bbox_w / img_w\n",
        "    norm_h = bbox_h / img_h\n",
        "    yolo_class_id = category_id - 1\n",
        "    yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "\n",
        "    # Salva o arquivo de anota√ß√£o\n",
        "    label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "    with open(os.path.join(labels_train_dir, label_file_name), 'a') as f:\n",
        "        f.write(yolo_format_str)\n",
        "\n",
        "    # Copia o arquivo de imagem do Google Drive para a pasta local do Colab\n",
        "    source_image_path = os.path.join(gdrive_image_path, file_name)\n",
        "    dest_image_path = os.path.join(images_train_dir, file_name)\n",
        "    if not os.path.exists(dest_image_path):\n",
        "        shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "print(\"\\nPrepara√ß√£o do dataset de x√≠caras conclu√≠da!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBojX-Tsdqy2",
        "outputId": "1de92499-14d7-4def-b722-ba27402c8652"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrutura de pastas criada em: /content/yolo_dataset_xicaras\n",
            "Dataset cont√©m 1 classe(s): xicara\n",
            "\n",
            "Processando anota√ß√µes e copiando imagens de x√≠caras...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [00:00<00:00, 127.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prepara√ß√£o do dataset de x√≠caras conclu√≠da!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando Arquivo de Configura√ß√£o do Dataset (YAML)"
      ],
      "metadata": {
        "id": "cnAziz_bdxtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Cria o dicion√°rio com as informa√ß√µes do novo dataset\n",
        "yaml_data = {\n",
        "    'train': os.path.join(base_dir, 'images', 'train'),\n",
        "    'val': os.path.join(base_dir, 'images', 'train'), # Usando o mesmo conjunto para valida√ß√£o\n",
        "    'nc': num_classes,\n",
        "    'names': class_names\n",
        "}\n",
        "\n",
        "# Salva o arquivo de configura√ß√£o com um novo nome\n",
        "yaml_file_path = '/content/dataset_xicaras.yaml'\n",
        "with open(yaml_file_path, 'w') as f:\n",
        "    yaml.dump(yaml_data, f, sort_keys=False)\n",
        "\n",
        "print(f\"Arquivo de configura√ß√£o '{yaml_file_path}' criado com sucesso:\")\n",
        "!cat {yaml_file_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcUVO5Rhd4i5",
        "outputId": "521031a6-5c06-4703-b39d-905da31e5466"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo de configura√ß√£o '/content/dataset_xicaras.yaml' criado com sucesso:\n",
            "train: /content/yolo_dataset_xicaras/images/train\n",
            "val: /content/yolo_dataset_xicaras/images/train\n",
            "nc: 1\n",
            "names:\n",
            "- xicara\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iniciando o Treinamento de Modelo - X√çCARAS"
      ],
      "metadata": {
        "id": "QrmweX3ed9Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Carrega um modelo pr√©-treinado (yolov8n.pt √© o menor e mais r√°pido)\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Inicia o treinamento\n",
        "results = model.train(\n",
        "    data=yaml_file_path,       # Usa o novo arquivo .yaml que criamos\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    project='yolo_training',   # Pasta principal para os resultados\n",
        "    name='xicaras_detector'    # Nome da subpasta espec√≠fica para este treinamento\n",
        ")\n",
        "\n",
        "print(\"\\nTreinamento de x√≠caras conclu√≠do!\")\n",
        "print(\"Os resultados, incluindo os pesos do modelo treinado, est√£o na pasta 'yolo_training/xicaras_detector'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8mz-9H3eB6A",
        "outputId": "ec1f064f-580e-4381-afc2-ddf77f1c0d2a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 101.0MB/s 0.1s\n",
            "Ultralytics 8.3.214 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset_xicaras.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=xicaras_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/yolo_training/xicaras_detector, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 25.9MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 114.7MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1617.3¬±523.5 MB/s, size: 70.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset_xicaras/labels/train... 38 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 38/38 841.2it/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_dataset_xicaras/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 485.4¬±221.5 MB/s, size: 56.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_xicaras/labels/train.cache... 38 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 38/38 28.5Kit/s 0.0s\n",
            "Plotting labels to /content/yolo_training/xicaras_detector/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolo_training/xicaras_detector\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      1.97G     0.9308      2.545      1.358         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 1.2it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.3it/s 1.5s\n",
            "                   all         38         38    0.00333          1      0.263       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      2.45G      0.935      2.575       1.45         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.1it/s 1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.9it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.501      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      2.47G      0.858      2.331      1.367         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.0it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.3it/s 0.5s\n",
            "                   all         38         38    0.00333          1      0.829      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      2.47G     0.6108      1.736      1.226         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.4it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.5it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.903      0.734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      2.49G      0.606      1.541      1.247         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 6.1it/s 0.3s\n",
            "                   all         38         38    0.00333          1      0.849      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      2.49G     0.6725      1.389      1.307         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.808      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      2.52G     0.6141      1.198      1.235         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.9it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.8it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.876      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      2.52G     0.6596      1.269      1.249         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.4it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38    0.00333          1      0.929      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      2.52G     0.5734       1.19      1.188         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.1it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38          1      0.405      0.934      0.716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      2.52G     0.6273      1.243       1.22         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.4it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.2it/s 0.4s\n",
            "                   all         38         38      0.961      0.651      0.967      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      2.54G     0.6212      1.131      1.182         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.8it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38      0.936      0.775      0.965      0.778\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      2.54G     0.6985      1.157       1.27         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.4it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.0it/s 0.7s\n",
            "                   all         38         38          1      0.832      0.995      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      2.54G     0.5881      1.114      1.182         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.4it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.9it/s 0.7s\n",
            "                   all         38         38      0.993          1      0.995      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      2.55G     0.6117     0.9986      1.193         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.9it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.1it/s 0.4s\n",
            "                   all         38         38      0.945      0.974       0.99       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      2.55G     0.8043      1.239      1.376         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.8it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38      0.945      0.868      0.984      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      2.55G     0.7403      1.204      1.284         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.0it/s 0.7s\n",
            "                   all         38         38      0.921      0.919      0.983      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      2.55G     0.5854       0.98      1.188         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.1it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.2it/s 0.5s\n",
            "                   all         38         38      0.839      0.895      0.901      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      2.55G     0.5792     0.9946      1.175         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 6.2it/s 0.3s\n",
            "                   all         38         38       0.69      0.816      0.867      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      2.55G     0.6483       1.06      1.241         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.0it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38      0.789      0.868       0.89      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      2.55G     0.5316     0.9002      1.114         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.8it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.9it/s 0.3s\n",
            "                   all         38         38       0.93      0.697      0.898       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      2.55G     0.5943      0.873      1.162         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.6it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 6.1it/s 0.3s\n",
            "                   all         38         38      0.902      0.729      0.904      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      2.55G     0.6702     0.9348       1.24         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.8it/s 0.5s\n",
            "                   all         38         38      0.887      0.825       0.92      0.583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      2.55G     0.6373      1.109      1.301         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.7it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.0it/s 0.7s\n",
            "                   all         38         38      0.894       0.89       0.96      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      2.55G     0.5925     0.9105      1.156         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.6it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.8it/s 0.7s\n",
            "                   all         38         38      0.922      0.935      0.974      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      2.57G     0.5599     0.8583      1.125         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.0it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 6.7it/s 0.3s\n",
            "                   all         38         38      0.874      0.921      0.955      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      2.57G     0.5106     0.8149      1.129         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.3it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38       0.83      0.903      0.934      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      2.57G     0.6345     0.8931      1.153         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.1it/s 0.4s\n",
            "                   all         38         38      0.899      0.947      0.959      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      2.58G     0.5399      0.866      1.173         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.1it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38       0.91      0.921      0.969      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50       2.6G     0.5625     0.8388      1.133         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.4it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.3it/s 0.4s\n",
            "                   all         38         38       0.91      0.921      0.969      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50       2.6G     0.5511     0.9022      1.168         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.1it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.6it/s 0.4s\n",
            "                   all         38         38          1      0.839      0.973      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50       2.6G     0.5227     0.8134      1.109         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.4it/s 0.4s\n",
            "                   all         38         38      0.901          1      0.984       0.79\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50       2.6G     0.5264     0.7759        1.1         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.9it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.4it/s 0.5s\n",
            "                   all         38         38      0.996      0.895      0.985      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      2.62G     0.5009       0.78      1.085         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.4it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.5it/s 0.6s\n",
            "                   all         38         38      0.996      0.895      0.985      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      2.62G     0.5259     0.8064      1.107         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.6it/s 0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.1it/s 0.6s\n",
            "                   all         38         38      0.935      0.947      0.986      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      2.62G     0.6273      0.852      1.197         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.9it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.8it/s 0.7s\n",
            "                   all         38         38      0.997      0.974      0.993      0.895\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      2.62G     0.4519     0.8006      1.094         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.8it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.0it/s 0.4s\n",
            "                   all         38         38      0.974      0.997      0.994      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      2.62G     0.4986      0.768      1.124         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.0it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.4it/s 0.4s\n",
            "                   all         38         38      0.974      0.997      0.994      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      2.62G      0.477     0.7373      1.052         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.4it/s 0.5s\n",
            "                   all         38         38      0.997          1      0.995      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      2.62G      0.523     0.8334      1.127         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.3it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.0it/s 0.4s\n",
            "                   all         38         38          1          1      0.995      0.913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      2.62G     0.5623      0.824      1.147         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.3it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.6it/s 0.4s\n",
            "                   all         38         38      0.997          1      0.995      0.907\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      2.62G      0.478      1.253       1.14          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.4it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.7it/s 0.7s\n",
            "                   all         38         38      0.997          1      0.995      0.907\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      2.62G     0.3543      1.073      1.043          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.7it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38      0.998          1      0.995      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      2.62G     0.4654      1.302      1.175          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 5.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.8it/s 0.7s\n",
            "                   all         38         38      0.998          1      0.995      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      2.62G     0.3206     0.9854      1.036          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.7it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.8it/s 0.5s\n",
            "                   all         38         38      0.997          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      2.62G     0.3723      1.024       1.03          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.9it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.3it/s 0.6s\n",
            "                   all         38         38      0.997          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      2.62G     0.3323     0.9969      1.029          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 7.1it/s 0.3s\n",
            "                   all         38         38      0.997          1      0.995      0.942\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      2.62G     0.3081     0.9614       1.01          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 6.7it/s 0.3s\n",
            "                   all         38         38      0.999          1      0.995      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      2.62G      0.302     0.9395     0.9774          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.7it/s 0.3s\n",
            "                   all         38         38      0.999          1      0.995      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      2.62G     0.3072      0.945     0.9993          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.5it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.0it/s 0.4s\n",
            "                   all         38         38      0.999          1      0.995      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      2.62G      0.313     0.9711     0.9569          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 7.4it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.9it/s 0.4s\n",
            "                   all         38         38      0.999          1      0.995      0.966\n",
            "\n",
            "50 epochs completed in 0.019 hours.\n",
            "Optimizer stripped from /content/yolo_training/xicaras_detector/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/yolo_training/xicaras_detector/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/yolo_training/xicaras_detector/weights/best.pt...\n",
            "Ultralytics 8.3.214 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.7it/s 0.4s\n",
            "                   all         38         38      0.999          1      0.995      0.963\n",
            "Speed: 0.3ms preprocess, 2.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolo_training/xicaras_detector\u001b[0m\n",
            "\n",
            "Treinamento de x√≠caras conclu√≠do!\n",
            "Os resultados, incluindo os pesos do modelo treinado, est√£o na pasta 'yolo_training/xicaras_detector'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo das m√©tricas do Treinamento - 25 √âpocas\n",
        "\n",
        "### Box(P) - Precis√£o (0.971): Quando o modelo diz \"isto √© uma x√≠cara\", ele est√° correto em 97.1% das vezes. Um resultado fant√°stico, com pouqu√≠ssimos alarmes falsos.\n",
        "\n",
        "### Box(R) - Recall (0.887): De todas as x√≠caras que realmente existiam nas imagens, o modelo conseguiu encontrar 88.7% delas. Tamb√©m √© um n√∫mero muito alto, mostrando que o modelo raramente deixa passar uma x√≠cara sem detectar.\n",
        "\n",
        "### mAP50 (0.989): Esta √© a m√©trica principal e o resultado √© quase perfeito: 98.9%. Isso indica que o modelo √© extremamente bom em localizar as x√≠caras corretamente. A performance √© significativamente superior √† do modelo de chaves na mesma etapa.\n",
        "\n",
        "### mAP50-95 (0.906): Este √© talvez o resultado mais impressionante. Um valor de 90.6% nesta m√©trica rigorosa √© excepcional. Ele nos diz que as caixas delimitadoras que o modelo desenha n√£o est√£o apenas no lugar certo, mas tamb√©m est√£o muito bem ajustadas ao tamanho e formato das x√≠caras."
      ],
      "metadata": {
        "id": "GiHVV65bjESK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo das m√©tricas do Treinamento - 50 √âpocas:\n",
        "\n",
        "### Box(P) - Precis√£o (0.999): Resultado Praticamente Perfeito. Uma precis√£o de 99.9% indica que quase todas as detec√ß√µes que o modelo fez estavam corretas. Ele praticamente n√£o cometeu erros de \"falso positivo\" (identificar um objeto que n√£o era uma x√≠cara). Isso o torna extremamente confi√°vel.\n",
        "\n",
        "### Box(R) - Recall (1): Resultado Perfeito. Um recall de 100% √© a pontua√ß√£o m√°xima. Significa que, de todas as x√≠caras que realmente existiam nas 38 imagens, o modelo encontrou TODAS. Ele n√£o deixou nenhuma passar despercebida, o que √© um feito fant√°stico.\n",
        "\n",
        "### mAP50 (0.995): Desempenho de Elite. A m√©trica principal, que combina precis√£o e recall, atingiu 99.5%. Este √© um resultado de alt√≠ssima qualidade, confirmando que o modelo localiza as x√≠caras com uma precis√£o quase perfeita.\n",
        "\n",
        "### mAP50-95 (0.963): Excepcional e Robusto. ste √©, talvez, o resultado mais impressionante. Um valor de 96.3% nesta m√©trica, que √© muito mais rigorosa, √© excepcional. Ele nos diz que as caixas delimitadoras que o modelo desenha n√£o est√£o apenas no lugar certo, mas tamb√©m est√£o muito bem ajustadas ao tamanho e formato das x√≠caras, mesmo sob crit√©rios de avalia√ß√£o muito exigentes.\n",
        "\n",
        "# Conclus√£o:\n",
        "\n",
        "### Este modelo de detec√ß√£o de x√≠caras atingiu um n√≠vel de desempenho de elite. A combina√ß√£o de precis√£o quase perfeita, recall perfeito e um mAP50-95 alt√≠ssimo indica que o modelo n√£o apenas aprendeu a identificar x√≠caras, mas o fez de forma extremamente robusta e precisa.\n",
        "\n",
        "### Diferente do modelo de chaves, que mostrou sinais de overfitting, este modelo parece ter aprendido as caracter√≠sticas essenciais das x√≠caras de uma maneira que o torna muito mais generaliz√°vel."
      ],
      "metadata": {
        "id": "ZJb82yxoYO4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Valida√ß√£o Dedicada - X√çCARAS"
      ],
      "metadata": {
        "id": "oQgOF1gtmIgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"--- Iniciando o Processo de Valida√ß√£o do Modelo de X√≠caras ---\")\n",
        "\n",
        "# --- 1. CONFIGURA√á√ÉO DOS CAMINHOS ---\n",
        "# Caminho para a pasta de IMAGENS de valida√ß√£o\n",
        "gdrive_val_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/validation'\n",
        "\n",
        "# Caminho para a pasta base onde o JSON de valida√ß√£o est√° localizado\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras'\n",
        "\n",
        "# Nome do seu arquivo JSON de valida√ß√£o (formato COCO)\n",
        "gdrive_val_json_name = 'labels_my-project-name_2025-10-14-04-17-44.json'\n",
        "gdrive_val_json_path = os.path.join(gdrive_base_path, gdrive_val_json_name)\n",
        "\n",
        "# Caminho para o seu melhor modelo TREINADO de x√≠caras\n",
        "model_path = '/content/yolo_training/xicaras_detector/weights/best.pt'\n",
        "\n",
        "# --- 2. PREPARA√á√ÉO DO DATASET DE VALIDA√á√ÉO ---\n",
        "print(f\"\\n[PASSO 1/3] Preparando o dataset de valida√ß√£o a partir de: {gdrive_val_path}\")\n",
        "\n",
        "base_dir_val = '/content/yolo_dataset_xicaras_validation'\n",
        "images_val_dir = os.path.join(base_dir_val, 'images', 'val')\n",
        "labels_val_dir = os.path.join(base_dir_val, 'labels', 'val')\n",
        "\n",
        "if os.path.exists(base_dir_val):\n",
        "    shutil.rmtree(base_dir_val)\n",
        "os.makedirs(images_val_dir, exist_ok=True)\n",
        "os.makedirs(labels_val_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    print(f\"Carregando anota√ß√µes de: {gdrive_val_json_path}\")\n",
        "    with open(gdrive_val_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    if 'annotations' not in coco_data or 'images' not in coco_data or 'categories' not in coco_data:\n",
        "        raise ValueError(\"Erro: O arquivo JSON n√£o parece estar no formato COCO.\")\n",
        "\n",
        "    images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "    categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    class_names = list(categories_info.values())\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\"Encontradas {len(coco_data['images'])} imagens e {len(coco_data['annotations'])} anota√ß√µes no JSON.\")\n",
        "\n",
        "    for ann in tqdm(coco_data['annotations'], desc=\"Processando anota√ß√µes\"):\n",
        "        if 'category_id' not in ann or 'bbox' not in ann:\n",
        "            continue\n",
        "\n",
        "        image_id = ann['image_id']\n",
        "        file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "        source_image_path = os.path.join(gdrive_val_path, file_name)\n",
        "        dest_image_path = os.path.join(images_val_dir, file_name)\n",
        "        if not os.path.exists(dest_image_path):\n",
        "            shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "        with open(os.path.join(labels_val_dir, label_file_name), 'a') as f:\n",
        "            category_id = ann['category_id']\n",
        "            bbox = ann['bbox']\n",
        "            x_min, y_min, bbox_w, bbox_h = bbox\n",
        "            x_center = (x_min + bbox_w / 2) / img_w\n",
        "            y_center = (y_min + bbox_h / 2) / img_h\n",
        "            norm_w = bbox_w / img_w\n",
        "            norm_h = bbox_h / img_h\n",
        "            yolo_class_id = category_id - 1\n",
        "            yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "            f.write(yolo_format_str)\n",
        "\n",
        "    print(\"Dataset de valida√ß√£o preparado com sucesso.\")\n",
        "\n",
        "    # --- 3. CRIA√á√ÉO DO ARQUIVO YAML ---\n",
        "    print(\"\\n[PASSO 2/3] Criando arquivo de configura√ß√£o 'validation_xicaras.yaml'\")\n",
        "    yaml_val_data = {\n",
        "        'train': images_val_dir,\n",
        "        'val': images_val_dir,\n",
        "        'nc': num_classes,\n",
        "        'names': class_names\n",
        "    }\n",
        "    yaml_val_file_path = '/content/validation_xicaras.yaml'\n",
        "    with open(yaml_val_file_path, 'w') as f:\n",
        "        yaml.dump(yaml_val_data, f, sort_keys=False)\n",
        "    !cat {yaml_val_file_path}\n",
        "\n",
        "    # --- 4. EXECU√á√ÉO DA VALIDA√á√ÉO ---\n",
        "    print(\"\\n[PASSO 3/3] Executando a valida√ß√£o...\")\n",
        "    model = YOLO(model_path)\n",
        "    validation_results = model.val(data=yaml_val_file_path)\n",
        "    print(\"\\n--- Processo de Valida√ß√£o Conclu√≠do ---\")\n",
        "\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(f\"\\nERRO CR√çTICO: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7oCrXy4mLXw",
        "outputId": "d5396f1e-7ced-4727-825f-b3ef2ad94167"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando o Processo de Valida√ß√£o do Modelo de X√≠caras ---\n",
            "\n",
            "[PASSO 1/3] Preparando o dataset de valida√ß√£o a partir de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/validation\n",
            "Carregando anota√ß√µes de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-14-04-17-44.json\n",
            "Encontradas 5 imagens e 5 anota√ß√µes no JSON.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando anota√ß√µes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 313.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset de valida√ß√£o preparado com sucesso.\n",
            "\n",
            "[PASSO 2/3] Criando arquivo de configura√ß√£o 'validation_xicaras.yaml'\n",
            "train: /content/yolo_dataset_xicaras_validation/images/val\n",
            "val: /content/yolo_dataset_xicaras_validation/images/val\n",
            "nc: 1\n",
            "names:\n",
            "- xicara\n",
            "\n",
            "[PASSO 3/3] Executando a valida√ß√£o...\n",
            "Ultralytics 8.3.214 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1585.7¬±389.1 MB/s, size: 61.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_xicaras_validation/labels/val... 5 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.1Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset_xicaras_validation/labels/val.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 3.9it/s 0.3s\n",
            "                   all          5          5       0.99          1      0.995      0.596\n",
            "Speed: 0.3ms preprocess, 31.7ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "\n",
            "--- Processo de Valida√ß√£o Conclu√≠do ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resumo de Valida√ß√£o Dedicada - X√çCARAS - 25 √âpocas\n",
        "\n",
        "### Box(P) - Precis√£o (0.949): A precis√£o de 94.9% √© excelente. Significa que praticamente todas as detec√ß√µes que o modelo fez foram corretas.\n",
        "\n",
        "### Box(R) - Recall (1): Este √© um resultado perfeito (100%). De todas as x√≠caras que existiam nas 5 imagens de valida√ß√£o, o modelo encontrou todas.\n",
        "\n",
        "### mAP50 (0.995): A m√©trica principal √© de 99.5%, o que √© praticamente a pontua√ß√£o m√°xima. Isso confirma que o modelo n√£o s√≥ encontra todas as x√≠caras, mas tamb√©m as localiza com alt√≠ssima precis√£o.\n",
        "\n",
        "### mAP50-95 (0.551): Este resultado √© o √∫nico ponto que merece aten√ß√£o. Houve uma queda em rela√ß√£o ao treino (de 90.6% para 55.1%). O que significa que, embora o modelo encontre todas as x√≠caras, a \"qualidade\" das caixas delimitadoras (o qu√£o justo o ret√¢ngulo fica ao redor do objeto) n√£o √© t√£o perfeita nas imagens de valida√ß√£o quanto era nas de treino. No entanto, um valor de 55.1% ainda √© considerado bom e funcional."
      ],
      "metadata": {
        "id": "xqA5UFV_mf6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo de Valida√ß√£o Dedicada - X√çCARAS - 50 √âpocas\n",
        "\n",
        "### Box(P) - Precis√£o (0.99): Quase Perfeito. Mede a exatid√£o das detec√ß√µes. De todas as vezes que o modelo disse \"isto √© uma x√≠cara\", ele estava certo em 99% das vezes. Este √© um resultado de elite. Significa que o modelo √© extremamente confi√°vel e quase nunca comete erros de \"falso positivo\" (identificar um objeto que n√£o √© uma x√≠cara).\n",
        "\n",
        "### Box(R) - Recall (1): Perfeito. Mede a capacidade do modelo de encontrar todos os objetos existentes. Um recall de 100% √© a pontua√ß√£o m√°xima.O modelo encontrou TODAS as x√≠caras que existiam nas 5 imagens de valida√ß√£o. Ele n√£o deixou nenhuma passar despercebida, o que √© um feito fant√°stico e o torna muito robusto.\n",
        "\n",
        "### mAP50 (0.995): Desempenho de Elite. A principal m√©trica, que combina precis√£o e recall. Uma detec√ß√£o √© considerada correta se a caixa prevista tiver pelo menos 50% de sobreposi√ß√£o com a caixa real. Uma pontua√ß√£o de 99.5% √© o mais pr√≥ximo da perfei√ß√£o que se pode esperar. Isso confirma que o modelo localiza as x√≠caras com uma precis√£o alt√≠ssima.\n",
        "\n",
        "### mAP50-95 (0.596): Bom e Consistente. Uma m√©trica muito mais rigorosa, que calcula a m√©dia da performance em 10 n√≠veis diferentes de exig√™ncia (de 50% a 95% de sobreposi√ß√£o). O valor de 59.6% √© bom. A queda em rela√ß√£o ao valor do treinamento (que era de 96.3%) √© esperada e normal. Isso nos diz que, embora o modelo encontre as x√≠caras perfeitamente, a delimita√ß√£o das caixas delimitadoras n√£o √© sempre milim√©trica em imagens novas, mas ainda assim √© muito funcional.\n",
        "\n",
        "# Conclus√£o:\n",
        "\n",
        "### O modelo de detec√ß√£o de x√≠caras √© excelente e confi√°vel. O fato de a m√©trica principal (mAP50) e o recall terem se mantido perfeitos na valida√ß√£o √© a melhor prova de que ele n√£o sofreu de overfitting. Ele aprendeu as caracter√≠sticas essenciais de uma \"x√≠cara\" de forma t√£o robusta que consegue aplicar esse conhecimento com a mesma efic√°cia em imagens que nunca viu antes."
      ],
      "metadata": {
        "id": "AKd95YVeZORv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste Modelo - X√çCARA"
      ],
      "metadata": {
        "id": "K9qn9Y10pZPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"--- Iniciando o Processo de Teste Final do Modelo de X√≠caras ---\")\n",
        "\n",
        "# --- 1. CONFIGURA√á√ÉO DOS CAMINHOS ---\n",
        "# Caminho para a pasta de IMAGENS de teste\n",
        "gdrive_test_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/test'\n",
        "\n",
        "# Caminho para a pasta base onde o JSON de teste est√° localizado\n",
        "gdrive_base_path = '/content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras'\n",
        "\n",
        "# Nome do seu arquivo JSON de teste (formato COCO)\n",
        "gdrive_test_json_name = 'labels_my-project-name_2025-10-14-04-32-33.json'\n",
        "gdrive_test_json_path = os.path.join(gdrive_base_path, gdrive_test_json_name)\n",
        "\n",
        "# Caminho para o seu melhor modelo TREINADO de x√≠caras\n",
        "model_path = '/content/yolo_training/xicaras_detector/weights/best.pt'\n",
        "\n",
        "# --- 2. PREPARA√á√ÉO DO DATASET DE TESTE ---\n",
        "print(f\"\\n[PASSO 1/3] Preparando o dataset de teste a partir de: {gdrive_test_path}\")\n",
        "\n",
        "base_dir_test = '/content/yolo_dataset_xicaras_test'\n",
        "images_test_dir = os.path.join(base_dir_test, 'images', 'test')\n",
        "labels_test_dir = os.path.join(base_dir_test, 'labels', 'test')\n",
        "\n",
        "if os.path.exists(base_dir_test):\n",
        "    shutil.rmtree(base_dir_test)\n",
        "os.makedirs(images_test_dir, exist_ok=True)\n",
        "os.makedirs(labels_test_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    print(f\"Carregando anota√ß√µes de: {gdrive_test_json_path}\")\n",
        "    with open(gdrive_test_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    if 'annotations' not in coco_data or 'images' not in coco_data or 'categories' not in coco_data:\n",
        "        raise ValueError(\"Erro: O arquivo JSON n√£o parece estar no formato COCO.\")\n",
        "\n",
        "    images_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco_data['images']}\n",
        "    categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    class_names = list(categories_info.values())\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\"Encontradas {len(coco_data['images'])} imagens e {len(coco_data['annotations'])} anota√ß√µes no JSON de teste.\")\n",
        "\n",
        "    for ann in tqdm(coco_data['annotations'], desc=\"Processando anota√ß√µes de teste\"):\n",
        "        if 'category_id' not in ann or 'bbox' not in ann:\n",
        "            continue\n",
        "\n",
        "        image_id = ann['image_id']\n",
        "        file_name, img_w, img_h = images_info[image_id]\n",
        "\n",
        "        source_image_path = os.path.join(gdrive_test_path, file_name)\n",
        "        dest_image_path = os.path.join(images_test_dir, file_name)\n",
        "        if not os.path.exists(dest_image_path):\n",
        "            shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
        "        with open(os.path.join(labels_test_dir, label_file_name), 'a') as f:\n",
        "            category_id = ann['category_id']\n",
        "            bbox = ann['bbox']\n",
        "            x_min, y_min, bbox_w, bbox_h = bbox\n",
        "            x_center = (x_min + bbox_w / 2) / img_w\n",
        "            y_center = (y_min + bbox_h / 2) / img_h\n",
        "            norm_w = bbox_w / img_w\n",
        "            norm_h = bbox_h / img_h\n",
        "            yolo_class_id = category_id - 1\n",
        "            yolo_format_str = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\"\n",
        "            f.write(yolo_format_str)\n",
        "\n",
        "    print(\"Dataset de teste preparado com sucesso.\")\n",
        "\n",
        "    # --- 3. CRIA√á√ÉO DO ARQUIVO YAML DE TESTE ---\n",
        "    print(\"\\n[PASSO 2/3] Criando arquivo de configura√ß√£o 'test_xicaras.yaml'\")\n",
        "    yaml_test_data = {\n",
        "        'train': images_test_dir,\n",
        "        'val': images_test_dir,   # Apontamos 'val' para o nosso conjunto de teste\n",
        "        'nc': num_classes,\n",
        "        'names': class_names\n",
        "    }\n",
        "    yaml_test_file_path = '/content/test_xicaras.yaml'\n",
        "    with open(yaml_test_file_path, 'w') as f:\n",
        "        yaml.dump(yaml_test_data, f, sort_keys=False)\n",
        "    !cat {yaml_test_file_path}\n",
        "\n",
        "    # --- 4. EXECU√á√ÉO DO TESTE FINAL ---\n",
        "    print(\"\\n[PASSO 3/3] Executando o teste final com o modelo treinado...\")\n",
        "    model = YOLO(model_path)\n",
        "    test_results = model.val(data=yaml_test_file_path)\n",
        "    print(\"\\n--- Processo de Teste Conclu√≠do ---\")\n",
        "\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(f\"\\nERRO CR√çTICO: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3H5iyVDpczm",
        "outputId": "25090ebc-0de8-4e34-c6f7-72914adc176f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando o Processo de Teste Final do Modelo de X√≠caras ---\n",
            "\n",
            "[PASSO 1/3] Preparando o dataset de teste a partir de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/test\n",
            "Carregando anota√ß√µes de: /content/drive/MyDrive/computer_vision_cap1/Computer_Vision_Cap1/xicaras/labels_my-project-name_2025-10-14-04-32-33.json\n",
            "Encontradas 5 imagens e 5 anota√ß√µes no JSON de teste.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando anota√ß√µes de teste: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 318.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset de teste preparado com sucesso.\n",
            "\n",
            "[PASSO 2/3] Criando arquivo de configura√ß√£o 'test_xicaras.yaml'\n",
            "train: /content/yolo_dataset_xicaras_test/images/test\n",
            "val: /content/yolo_dataset_xicaras_test/images/test\n",
            "nc: 1\n",
            "names:\n",
            "- xicara\n",
            "\n",
            "[PASSO 3/3] Executando o teste final com o modelo treinado...\n",
            "Ultralytics 8.3.214 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1926.6¬±413.2 MB/s, size: 62.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset_xicaras_test/labels/test... 5 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.2Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset_xicaras_test/labels/test.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 6.1it/s 0.2s\n",
            "                   all          5          5      0.991          1      0.995      0.671\n",
            "Speed: 0.6ms preprocess, 6.5ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "\n",
            "--- Processo de Teste Conclu√≠do ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resumo do Teste Final do Modelo - X√çCARAS - 25 √âpocas\n",
        "\n",
        "### Box(P) - Precis√£o (1): Uma precis√£o de 100% significa que todas as detec√ß√µes quemodelo fez estavam corretas. Ele n√£o cometeu nenhum erro de \"falso positivo\" (ou seja, nunca identificou um objeto que n√£o era uma x√≠cara). Isso torna o modelo extremamente confi√°vel.\n",
        "\n",
        "### Box(R) - Recall (0.976): Um resultado quase perfeito (97.6%). O modelo encontrou praticamente todas as x√≠caras que existiam nas imagens de teste. √â um desempenho extremamente robusto.\n",
        "\n",
        "### mAP50 (0.995): A m√©trica geral de desempenho √© de 99.5%, o que √© o mais pr√≥ximo da perfei√ß√£o que se pode esperar. Isso confirma que o modelo √© extremamente preciso na localiza√ß√£o das x√≠caras.\n",
        "\n",
        "### mAP50-95 (0.55): Este resultado permaneceu consistente com o da valida√ß√£o (55%). Isso mostra que, embora o modelo encontre os objetos com precis√£o quase perfeita, a dimens√£o das caixas delimitadoras √© boa, mas n√£o perfeita, o que √© um comportamento totalmente normal e aceit√°vel para um modelo de alto desempenho.\n",
        "\n",
        "# Conclus√£o\n",
        "\n",
        "### O fato de as m√©tricas de teste serem quase id√™nticas (e em precis√£o, at√© melhores) √†s da valida√ß√£o √© a prova definitiva de que o modelo generalizou de forma brilhante. Ele n√£o apenas \"decorou\" as imagens de treino, mas realmente aprendeu as caracter√≠sticas que definem uma x√≠cara e consegue aplicar esse conhecimento de forma confi√°vel a imagens completamente novas."
      ],
      "metadata": {
        "id": "qRYnwgf2px82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Teste Final do Modelo - X√çCARAS - 50 √âpocas\n",
        "\n",
        "### Box(P) - Precis√£o (0.991): Quase Perfeito.Mede a exatid√£o das detec√ß√µes. De todas as vezes que o modelo disse \"isto √© uma x√≠cara\", ele estava certo em 99.1% das vezes. Este √© um resultado de elite. Significa que o modelo √© extremamente confi√°vel e quase nunca comete erros de \"falso positivo\" (identificar um objeto que n√£o √© uma x√≠cara).\n",
        "\n",
        "### Mede a capacidade do modelo de encontrar todos os objetos existentes. Um recall de 100% √© a pontua√ß√£o m√°xima. O modelo encontrou todas as x√≠caras que existiam nas 5 imagens de teste. Ele n√£o deixou nenhuma passar despercebida, o que √© um feito fant√°stico e o torna muito robusto.\n",
        "\n",
        "\n",
        "### mAP50 (0.995): Desempenho de Elite. A sua principal m√©trica, que combina precis√£o e recall. Uma detec√ß√£o √© considerada correta se a caixa prevista tiver pelo menos 50% de sobreposi√ß√£o com a caixa real.Uma pontua√ß√£o de 99.5% √© o mais pr√≥ximo da perfei√ß√£o que se pode esperar. Isso confirma que o modelo localiza as x√≠caras com uma precis√£o alt√≠ssima.\n",
        "\n",
        "\n",
        "### mAP50-95 (0.671): Muito Bom e Consistente. Uma m√©trica muito mais rigorosa, que calcula a m√©dia da performance em 10 n√≠veis diferentes de exig√™ncia (de 50% a 95% de sobreposi√ß√£o). O valor de 67.1% √© muito bom e, mais importante, √© consistente e at√© melhor que o resultado da valida√ß√£o (que foi 59.6%). Isso mostra que as caixas delimitadoras s√£o bem ajustadas e que o modelo manteve sua qualidade sob crit√©rios mais rigorosos.\n",
        "\n",
        "\n",
        "# Conclus√£o:\n",
        "\n",
        "### O resultado mais importante aqui √© a consist√™ncia e a robustez. O fato de as m√©tricas de teste serem praticamente id√™nticas (ou at√© melhores) √†s da valida√ß√£o √© a prova definitiva de que o modelo n√£o sofreu de overfitting e generaliza de forma brilhante. Ele n√£o apenas \"decorou\" as imagens de treino; ele realmente \"aprendeu\" o que √© uma x√≠cara e consegue aplicar esse conhecimento com a mesma efic√°cia em imagens completamente novas."
      ],
      "metadata": {
        "id": "L-T8SBBmacao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclus√£o Definitiva - Comparativo Chaves x X√≠caras\n",
        "\n",
        "\n",
        "## Ao comparar os dois modelos, a conclus√£o mais importante n√£o √© apenas que um √© \"melhor\" que o outro, mas por que isso aconteceu:\n",
        "\n",
        "### A qualidade e a variedade dos dados de treinamento s√£o o fator mais determinante para o sucesso de um modelo de vis√£o computacional.\n",
        "\n",
        "### O trabalho demonstrou isso perfeitamente na pr√°tica. O modelo de x√≠caras foi um sucesso porque os dados permitiram que ele generalizasse. O modelo de chaves, apesar de usar a mesma tecnologia e o mesmo processo, teve dificuldades porque seus dados de treino n√£o foram suficientes para prepar√°-lo para a variedade do mundo real.\n",
        "\n",
        "### Houve sucesso n√£o apenas o treinamento de dois modelos, mas tamb√©m uma jornada completa de diagn√≥stico e an√°lise."
      ],
      "metadata": {
        "id": "eSTn-nNubyiH"
      }
    }
  ]
}